{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fundusdata.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOK+8Dj3UaqSCRIpIe/tixW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hihi5456/pytorch/blob/main/Fundusdata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7TZFTXDMW9T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f189984c-ba38-40ca-edd8-b3631484a2b9"
      },
      "source": [
        " !pip install adabelief-pytorch\n",
        "!pip install timm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting adabelief-pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/b7/5f/7d86b3688b4c9113af460205f09820fb9e6f2691e6fa63df3ec0d5de1ce5/adabelief_pytorch-0.2.1-py3-none-any.whl\n",
            "Requirement already satisfied: tabulate>=0.7 in /usr/local/lib/python3.7/dist-packages (from adabelief-pytorch) (0.8.9)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from adabelief-pytorch) (1.8.1+cu101)\n",
            "Collecting colorama>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->adabelief-pytorch) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->adabelief-pytorch) (3.7.4.3)\n",
            "Installing collected packages: colorama, adabelief-pytorch\n",
            "Successfully installed adabelief-pytorch-0.2.1 colorama-0.4.4\n",
            "Collecting timm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/89/d94f59780b5dd973154bf506d8ce598f6bfe7cc44dd445d644d6d3be8c39/timm-0.4.5-py3-none-any.whl (287kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 11.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.9.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXlJpJWjMBAt",
        "outputId": "b4ced94a-d934-49f0-8752-feef09e53283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        }
      },
      "source": [
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "import torch.utils.data.dataloader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset,ConcatDataset\n",
        "import adabelief_pytorch\n",
        "import numpy  as np\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, auc\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c9042c75a42d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mConcatDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0madabelief_pytorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m  \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'adabelief_pytorch'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI24FnUUUek5"
      },
      "source": [
        "from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_INCEPTION_MEAN, IMAGENET_INCEPTION_STD\n",
        "from timm.models.efficientnet_blocks import round_channels, resolve_bn_args, resolve_act_layer, BN_EPS_TF_DEFAULT\n",
        "from timm.models.efficientnet_builder import EfficientNetBuilder, decode_arch_def, efficientnet_init_weights\n",
        "from timm.models.features import FeatureInfo, FeatureHooks\n",
        "from timm.models.helpers import build_model_with_cfg, default_cfg_for_features\n",
        "from timm.models.layers import create_conv2d, create_classifier\n",
        "from timm.models.registry import register_model\n",
        "import timm\n",
        "import timm.models.efficientnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJk32gm8MaKw"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "torch.manual_seed(456)\n",
        "if device =='cuda':\n",
        "    torch.cuda.manual_seed_all(456)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUw8KzrIAMoO"
      },
      "source": [
        "class skipblock(nn.Module):\n",
        "  def __init__(self, in_channel,out_channel,outsize):\n",
        "    super(skipblock, self).__init__()\n",
        "    \n",
        "    \n",
        "    self.conv0=nn.Conv2d(in_channel,out_channel,1)\n",
        "    self.silu=nn.SiLU()\n",
        "    \n",
        "    self.block=nn.Sequential(\n",
        "                    \n",
        "            nn.Conv2d(out_channel, 64*in_channel, 1),\n",
        "            nn.BatchNorm2d(in_channel*64),         \n",
        "            nn.SiLU(),\n",
        "            nn.Dropout2d(),\n",
        "            \n",
        "\n",
        "            nn.Conv2d(in_channel*64, in_channel*64, 3, 1, 1),\n",
        "            nn.BatchNorm2d(in_channel*64),          \n",
        "            nn.SiLU(),\n",
        "            nn.Dropout2d(),\n",
        "\n",
        "            nn.Conv2d(in_channel*64,out_channel,1),\n",
        "            nn.BatchNorm2d(out_channel),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout2d(),\n",
        "            \n",
        "        )\n",
        "    \n",
        "    self.bn=nn.BatchNorm2d(out_channel)\n",
        "    self.pool=nn.AdaptiveAvgPool2d(outsize)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    out=self.conv0(x)\n",
        "    out=self.silu(out)\n",
        "    nn.Dropout2d()\n",
        "    skip=out\n",
        "    #print(out.shape)\n",
        "    out=self.block(out)\n",
        "    #print(out.shape)\n",
        "    out=out+skip\n",
        "    #print(out.shape)\n",
        "    out=self.bn(out)\n",
        "    out=self.pool(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KruW8Wp0MsOE"
      },
      "source": [
        "#gelu=nn.GELU()\n",
        "class testblock1(nn.Module):\n",
        "    def __init__(self,ni,num_class):\n",
        "        super(testblock1, self).__init__()\n",
        "  \n",
        "        self.block0=skipblock(ni,32,300)\n",
        "        \n",
        "        self.block1=skipblock(32,3,100)\n",
        "        \n",
        "        self.block2=skipblock(3,1,10)\n",
        "        \n",
        "     \n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(1*10*10,num_class),\n",
        "            \n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        \n",
        "        out=self.block0(x)\n",
        "        out=self.block1(out)\n",
        "        out=self.block2(out)\n",
        "\n",
        "\n",
        "        out = out.view(out.size(0),-1)\n",
        "        out=self.classifier(out)\n",
        "        \n",
        "        return out\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIUzslrD-3Cw"
      },
      "source": [
        "model=timm.models.efficientnet_l2(pretrained=False)\n",
        "model.reset_classifier(39)\n",
        "model.drop_rate=0.5\n",
        "\n",
        "model=model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJDzxyTx_MTq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84SWd1P_MvaO"
      },
      "source": [
        "model=testblock1(3,39).to(device)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZuDsLGbUhuf"
      },
      "source": [
        "model=timm.models.efficientnet.efficientnet_b7(pretrained=False).to(device)\n",
        "model.reset_classifier(39)\n",
        "model.drop_rate=0.5\n",
        "model=model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "hofEy7-ujMfg",
        "outputId": "3ad0d5c0-f1b8-453f-cd90-3587955c4521"
      },
      "source": [
        "a=torch.rand((1,3,600,600)).to(device)\n",
        "model(a)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-0163ee08cd81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-d092112eade2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-e9e7f3af9f18>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mskip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m#print(out.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;31m#print(out.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             self.weight, self.bias, bn_training, exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m     return torch.batch_norm(\n\u001b[0;32m-> 2150\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m     )\n\u001b[1;32m   2152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 264.00 MiB (GPU 0; 15.78 GiB total capacity; 13.77 GiB already allocated; 252.75 MiB free; 14.24 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTH2gucTMd-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac9e6ed-7384-4637-c034-f428a188aa9a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BK3ks9mUKVc"
      },
      "source": [
        "PATH='/content/gdrive/MyDrive/Colab Notebooks/fundusdataset/1000images/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBpvKMsU-PrU"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "     transforms.RandomRotation(45),\n",
        "     transforms.RandomHorizontalFlip(),\n",
        "     transforms.ToTensor(),\n",
        "     \n",
        "     transforms.Resize((600,600)),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "     ]\n",
        "     )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv9ie854UO21"
      },
      "source": [
        "fundus_data = torchvision.datasets.ImageFolder(root=PATH,transform=transform)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVNkMs9J_6vB"
      },
      "source": [
        "train_size=int(0.8*len(fundus_data))\n",
        "test_size=len(fundus_data)-train_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdYKtd5UAge-"
      },
      "source": [
        "train_set, test_set=torch.utils.data.random_split(fundus_data,[train_size,test_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb29JkY2YryJ"
      },
      "source": [
        "torch.save(train_set,PATH+'trainset.csv')\n",
        "torch.save(test_set,PATH+'testset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi2t5zzJNKll"
      },
      "source": [
        "train_set=torch.load(PATH+'trainset.csv')\n",
        "test_set=torch.load(PATH+'testset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7s8LnZ7_A6w"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_set,drop_last=True,\n",
        "                                          batch_size=8,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=2,\n",
        "                                          )\n",
        "test_loader = torch.utils.data.DataLoader(test_set,\n",
        "                                          batch_size=1,\n",
        "                                          shuffle=False,\n",
        "                                          num_workers=4,\n",
        "                                          )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeoswJ04BYjv",
        "outputId": "f6e4b4d4-a495-48c4-9bad-57d2374938b8"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "optimizer=adabelief_pytorch.AdaBelief(model.parameters(),lr=0.001)\n",
        "#lr_sche = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "Rectification enabled in AdaBelief\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOV8Mv4NBfwc",
        "outputId": "7c8bd5b9-32ef-4b7b-e73d-e44113a82fe5"
      },
      "source": [
        "trainedepochs=0\n",
        "print(len(train_loader))\n",
        "\n",
        "epochs = 500\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  \n",
        "  running_loss = 0.0\n",
        "\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels = data\n",
        "    inputs=inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward + backward + optimize\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    \n",
        "    \n",
        "       # (numarray.max()/numarray[labels[0][0].to(torch.int).tolist()-1])\n",
        "    #loss = (1/numnum[labels[0][0].to(torch.int).tolist()-1])*criterion(outputs, labels.to(torch.float)/10)\n",
        "    loss = criterion(outputs, labels)\n",
        "    \n",
        "    #print( (numnum.max()/numnum[labels[0][0].to(torch.int).tolist()-1]))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "    running_loss += loss.item()\n",
        "    if i % 20 == 19:    \n",
        "      print('[%d, %5d] loss: %.3f' %\n",
        "            (epoch + 1, i + 1, running_loss / 20))\n",
        "      running_loss = 0.0\n",
        "    #lr_sche.step()\n",
        "  \n",
        "  if epoch % 50==49:\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for data in test_loader:\n",
        "        \n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        \n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        \n",
        "        total += labels.size(0)\n",
        "        #print(predicted ,labels)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "      print('Accuracy of the network on the {} test images: {} %%'.format(len(test_set),\n",
        "                100 * correct / total))\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "  #if ( epoch==100 or epoch==150 or epoch==200 or epoch==250 or epoch==300 or epoch==350 or epoch==400 or epoch==450 or epoch==500 or epoch==550):\n",
        "      \n",
        "  if (epoch==100 or epoch==200 or epoch==300 or  epoch==400 or epoch==500 ):\n",
        "    torch.save(optimizer.state_dict, PATH+'optimizer{}.pt'.format(trainedepochs+epoch))\n",
        "    torch.save(model.state_dict,PATH+'model{}.pt'.format(trainedepochs+epoch))\n",
        "\n",
        "        \n",
        "        \n",
        "      \n",
        "      # loop over the dataset multiple times\n",
        "\n",
        "    #Check Accuracy\n",
        "    #acc = acc_check(resnet50, testloader, epoch, save=1)\n",
        "    \n",
        "    \n",
        "torch.save(model.state_dict,PATH+'model{}.pt'.format(trainedepochs+epochs))\n",
        "torch.save(optimizer.state_dict, PATH+'optimizer{}.pt'.format(trainedepochs+epochs))\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n",
            "[1,    20] loss: 3.737\n",
            "[1,    40] loss: 3.700\n",
            "[1,    60] loss: 3.698\n",
            "[1,    80] loss: 3.737\n",
            "[1,   100] loss: 3.691\n",
            "[2,    20] loss: 3.635\n",
            "[2,    40] loss: 3.717\n",
            "[2,    60] loss: 3.650\n",
            "[2,    80] loss: 3.538\n",
            "[2,   100] loss: 3.592\n",
            "[3,    20] loss: 3.516\n",
            "[3,    40] loss: 3.543\n",
            "[3,    60] loss: 3.449\n",
            "[3,    80] loss: 3.447\n",
            "[3,   100] loss: 3.441\n",
            "[4,    20] loss: 3.395\n",
            "[4,    40] loss: 3.435\n",
            "[4,    60] loss: 3.348\n",
            "[4,    80] loss: 3.433\n",
            "[4,   100] loss: 3.446\n",
            "[5,    20] loss: 3.311\n",
            "[5,    40] loss: 3.333\n",
            "[5,    60] loss: 3.407\n",
            "[5,    80] loss: 3.291\n",
            "[5,   100] loss: 3.301\n",
            "[6,    20] loss: 3.195\n",
            "[6,    40] loss: 3.273\n",
            "[6,    60] loss: 3.095\n",
            "[6,    80] loss: 3.323\n",
            "[6,   100] loss: 3.350\n",
            "[7,    20] loss: 3.122\n",
            "[7,    40] loss: 3.248\n",
            "[7,    60] loss: 3.135\n",
            "[7,    80] loss: 3.323\n",
            "[7,   100] loss: 3.168\n",
            "[8,    20] loss: 3.181\n",
            "[8,    40] loss: 3.234\n",
            "[8,    60] loss: 3.277\n",
            "[8,    80] loss: 3.058\n",
            "[8,   100] loss: 3.044\n",
            "[9,    20] loss: 3.116\n",
            "[9,    40] loss: 3.083\n",
            "[9,    60] loss: 3.037\n",
            "[9,    80] loss: 3.133\n",
            "[9,   100] loss: 3.176\n",
            "[10,    20] loss: 3.152\n",
            "[10,    40] loss: 3.038\n",
            "[10,    60] loss: 3.026\n",
            "[10,    80] loss: 3.113\n",
            "[10,   100] loss: 3.070\n",
            "[11,    20] loss: 3.022\n",
            "[11,    40] loss: 3.054\n",
            "[11,    60] loss: 2.962\n",
            "[11,    80] loss: 3.010\n",
            "[11,   100] loss: 3.143\n",
            "[12,    20] loss: 2.997\n",
            "[12,    40] loss: 3.015\n",
            "[12,    60] loss: 2.981\n",
            "[12,    80] loss: 2.886\n",
            "[12,   100] loss: 3.041\n",
            "[13,    20] loss: 2.859\n",
            "[13,    40] loss: 3.012\n",
            "[13,    60] loss: 2.929\n",
            "[13,    80] loss: 2.847\n",
            "[13,   100] loss: 3.054\n",
            "[14,    20] loss: 2.877\n",
            "[14,    40] loss: 2.765\n",
            "[14,    60] loss: 2.981\n",
            "[14,    80] loss: 2.793\n",
            "[14,   100] loss: 2.843\n",
            "[15,    20] loss: 2.808\n",
            "[15,    40] loss: 2.790\n",
            "[15,    60] loss: 2.878\n",
            "[15,    80] loss: 2.904\n",
            "[15,   100] loss: 2.915\n",
            "[16,    20] loss: 2.747\n",
            "[16,    40] loss: 2.969\n",
            "[16,    60] loss: 2.791\n",
            "[16,    80] loss: 2.765\n",
            "[16,   100] loss: 2.828\n",
            "[17,    20] loss: 2.634\n",
            "[17,    40] loss: 2.888\n",
            "[17,    60] loss: 2.744\n",
            "[17,    80] loss: 2.806\n",
            "[17,   100] loss: 2.890\n",
            "[18,    20] loss: 2.826\n",
            "[18,    40] loss: 2.704\n",
            "[18,    60] loss: 2.803\n",
            "[18,    80] loss: 2.773\n",
            "[18,   100] loss: 2.814\n",
            "[19,    20] loss: 2.665\n",
            "[19,    40] loss: 2.791\n",
            "[19,    60] loss: 2.695\n",
            "[19,    80] loss: 2.623\n",
            "[19,   100] loss: 2.744\n",
            "[20,    20] loss: 2.653\n",
            "[20,    40] loss: 2.850\n",
            "[20,    60] loss: 2.694\n",
            "[20,    80] loss: 2.702\n",
            "[20,   100] loss: 2.677\n",
            "[21,    20] loss: 2.503\n",
            "[21,    40] loss: 2.572\n",
            "[21,    60] loss: 2.747\n",
            "[21,    80] loss: 2.701\n",
            "[21,   100] loss: 2.762\n",
            "[22,    20] loss: 2.695\n",
            "[22,    40] loss: 2.619\n",
            "[22,    60] loss: 2.527\n",
            "[22,    80] loss: 2.745\n",
            "[22,   100] loss: 2.555\n",
            "[23,    20] loss: 2.471\n",
            "[23,    40] loss: 2.497\n",
            "[23,    60] loss: 2.742\n",
            "[23,    80] loss: 2.665\n",
            "[23,   100] loss: 2.468\n",
            "[24,    20] loss: 2.436\n",
            "[24,    40] loss: 2.592\n",
            "[24,    60] loss: 2.478\n",
            "[24,    80] loss: 2.569\n",
            "[24,   100] loss: 2.708\n",
            "[25,    20] loss: 2.581\n",
            "[25,    40] loss: 2.531\n",
            "[25,    60] loss: 2.565\n",
            "[25,    80] loss: 2.595\n",
            "[25,   100] loss: 2.415\n",
            "[26,    20] loss: 2.555\n",
            "[26,    40] loss: 2.505\n",
            "[26,    60] loss: 2.691\n",
            "[26,    80] loss: 2.579\n",
            "[26,   100] loss: 2.625\n",
            "[27,    20] loss: 2.529\n",
            "[27,    40] loss: 2.574\n",
            "[27,    60] loss: 2.473\n",
            "[27,    80] loss: 2.466\n",
            "[27,   100] loss: 2.566\n",
            "[28,    20] loss: 2.427\n",
            "[28,    40] loss: 2.660\n",
            "[28,    60] loss: 2.492\n",
            "[28,    80] loss: 2.530\n",
            "[28,   100] loss: 2.418\n",
            "[29,    20] loss: 2.402\n",
            "[29,    40] loss: 2.662\n",
            "[29,    60] loss: 2.334\n",
            "[29,    80] loss: 2.565\n",
            "[29,   100] loss: 2.412\n",
            "[30,    20] loss: 2.593\n",
            "[30,    40] loss: 2.457\n",
            "[30,    60] loss: 2.417\n",
            "[30,    80] loss: 2.527\n",
            "[30,   100] loss: 2.490\n",
            "[31,    20] loss: 2.624\n",
            "[31,    40] loss: 2.367\n",
            "[31,    60] loss: 2.350\n",
            "[31,    80] loss: 2.401\n",
            "[31,   100] loss: 2.432\n",
            "[32,    20] loss: 2.137\n",
            "[32,    40] loss: 2.537\n",
            "[32,    60] loss: 2.404\n",
            "[32,    80] loss: 2.554\n",
            "[32,   100] loss: 2.467\n",
            "[33,    20] loss: 2.463\n",
            "[33,    40] loss: 2.632\n",
            "[33,    60] loss: 2.316\n",
            "[33,    80] loss: 2.228\n",
            "[33,   100] loss: 2.482\n",
            "[34,    20] loss: 2.297\n",
            "[34,    40] loss: 2.405\n",
            "[34,    60] loss: 2.432\n",
            "[34,    80] loss: 2.463\n",
            "[34,   100] loss: 2.594\n",
            "[35,    20] loss: 2.380\n",
            "[35,    40] loss: 2.271\n",
            "[35,    60] loss: 2.478\n",
            "[35,    80] loss: 2.435\n",
            "[35,   100] loss: 2.362\n",
            "[36,    20] loss: 2.223\n",
            "[36,    40] loss: 2.385\n",
            "[36,    60] loss: 2.571\n",
            "[36,    80] loss: 2.457\n",
            "[36,   100] loss: 2.527\n",
            "[37,    20] loss: 2.144\n",
            "[37,    40] loss: 2.434\n",
            "[37,    60] loss: 2.422\n",
            "[37,    80] loss: 2.487\n",
            "[37,   100] loss: 2.317\n",
            "[38,    20] loss: 2.480\n",
            "[38,    40] loss: 2.403\n",
            "[38,    60] loss: 2.461\n",
            "[38,    80] loss: 2.225\n",
            "[38,   100] loss: 2.412\n",
            "[39,    20] loss: 2.213\n",
            "[39,    40] loss: 2.478\n",
            "[39,    60] loss: 2.404\n",
            "[39,    80] loss: 2.430\n",
            "[39,   100] loss: 2.403\n",
            "[40,    20] loss: 2.228\n",
            "[40,    40] loss: 2.223\n",
            "[40,    60] loss: 2.335\n",
            "[40,    80] loss: 2.397\n",
            "[40,   100] loss: 2.282\n",
            "[41,    20] loss: 2.106\n",
            "[41,    40] loss: 2.249\n",
            "[41,    60] loss: 2.425\n",
            "[41,    80] loss: 2.308\n",
            "[41,   100] loss: 2.436\n",
            "[42,    20] loss: 2.163\n",
            "[42,    40] loss: 2.430\n",
            "[42,    60] loss: 2.320\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blsQVexeeW6-"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "model.eval() \n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        \n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "         \n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        \n",
        "        total += labels.size(0)\n",
        "        #print(predicted ,labels)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the {} test images: {} %%'.format(len(test_set),\n",
        "    100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}