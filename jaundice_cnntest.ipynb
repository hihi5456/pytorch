{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "jaundice_cnntest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG3e4Dp4xwgY",
        "outputId": "7ed83695-2484-4552-aa8d-a936a0f167d0"
      },
      "source": [
        "!pip install adabelief-pytorch\r\n",
        "!pip install timm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting adabelief-pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/b7/5f/7d86b3688b4c9113af460205f09820fb9e6f2691e6fa63df3ec0d5de1ce5/adabelief_pytorch-0.2.1-py3-none-any.whl\n",
            "Requirement already satisfied: tabulate>=0.7 in /usr/local/lib/python3.7/dist-packages (from adabelief-pytorch) (0.8.9)\n",
            "Collecting colorama>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from adabelief-pytorch) (1.8.0+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->adabelief-pytorch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->adabelief-pytorch) (1.19.5)\n",
            "Installing collected packages: colorama, adabelief-pytorch\n",
            "Successfully installed adabelief-pytorch-0.2.1 colorama-0.4.4\n",
            "Collecting timm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/89/d94f59780b5dd973154bf506d8ce598f6bfe7cc44dd445d644d6d3be8c39/timm-0.4.5-py3-none-any.whl (287kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 13.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.9.0+cu101)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.8.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.7.4.3)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me9_mho50U8s"
      },
      "source": [
        "import torchvision\r\n",
        "from torchvision import transforms\r\n",
        "\r\n",
        "import torch.utils.data.dataloader\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.utils.data import Dataset,ConcatDataset\r\n",
        "import adabelief_pytorch\r\n",
        "import numpy  as np\r\n",
        "\r\n",
        "from sklearn.metrics import roc_auc_score, auc\r\n",
        "from scipy import stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYQObncg17pn"
      },
      "source": [
        "import torchvision.models.vgg as vgg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nPwEByroxFE"
      },
      "source": [
        "from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_INCEPTION_MEAN, IMAGENET_INCEPTION_STD\r\n",
        "from timm.models.efficientnet_blocks import round_channels, resolve_bn_args, resolve_act_layer, BN_EPS_TF_DEFAULT\r\n",
        "from timm.models.efficientnet_builder import EfficientNetBuilder, decode_arch_def, efficientnet_init_weights\r\n",
        "from timm.models.features import FeatureInfo, FeatureHooks\r\n",
        "from timm.models.helpers import build_model_with_cfg, default_cfg_for_features\r\n",
        "from timm.models.layers import create_conv2d, create_classifier\r\n",
        "from timm.models.registry import register_model\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BN7V7QX4eQx"
      },
      "source": [
        "import timm\r\n",
        "import timm.models.efficientnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csJd83D_LbDo"
      },
      "source": [
        "import timm.models.vision_transformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4pQpPSB_Hto"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
        "\r\n",
        "torch.manual_seed(444)\r\n",
        "if device =='cuda':\r\n",
        "    torch.cuda.manual_seed_all(444)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LC3hoSZAFsA"
      },
      "source": [
        "model=timm.models.efficientnet_b0(pretrained=False)\r\n",
        "#model2=timm.models.vision_transformer.vit_large_patch16_224(pretrained=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bL3bs8ENCEPp",
        "outputId": "aae84306-3b92-4452-835b-f7fa69054f69"
      },
      "source": [
        "model1.parameters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of EfficientNet(\n",
              "  (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (act1): SiLU(inplace=True)\n",
              "  (blocks): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): DepthwiseSeparableConv(\n",
              "        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): InvertedResidual(\n",
              "        (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): InvertedResidual(\n",
              "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): InvertedResidual(\n",
              "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
              "        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): InvertedResidual(\n",
              "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): InvertedResidual(\n",
              "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): InvertedResidual(\n",
              "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): InvertedResidual(\n",
              "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): InvertedResidual(\n",
              "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
              "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): InvertedResidual(\n",
              "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "        (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): InvertedResidual(\n",
              "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "        (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): InvertedResidual(\n",
              "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "        (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): InvertedResidual(\n",
              "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "        (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): InvertedResidual(\n",
              "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "        (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): InvertedResidual(\n",
              "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "        (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): InvertedResidual(\n",
              "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): SiLU(inplace=True)\n",
              "        (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act2): SiLU(inplace=True)\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (bn2): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (act2): SiLU(inplace=True)\n",
              "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)\n",
              "  (classifier): Linear(in_features=1280, out_features=1000, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MR5LSk5DWCR"
      },
      "source": [
        "model3=torchvision.models.vgg16(pretrained=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCKmCfM1Drj1",
        "outputId": "96969733-c5ab-4ce3-c1d0-5b15e7b663fd"
      },
      "source": [
        "sum(p.numel() for p in model3.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "138357544"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpU8JRU7C2Zr",
        "outputId": "4cd2d94e-dc04-48a8-819a-e8e88d9f17c8"
      },
      "source": [
        "sum(p.numel() for p in model1.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5288548"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-pSCl5uDN7Z",
        "outputId": "57ee08ad-4a71-4f25-a8c3-1c5953c851a7"
      },
      "source": [
        "sum(p.numel() for p in model2.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "304326632"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYAPCAy1L7Te"
      },
      "source": [
        "model=timm.models.mnasnet_075(pretrained=False)\r\n",
        "model.reset_classifier(1)\r\n",
        "model.drop_rate=0.5\r\n",
        "model=model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89uXsHbJlHrK"
      },
      "source": [
        "model=timm.models.efficientnet.efficientnet_b0(pretrained=False).to(device)\r\n",
        "model.reset_classifier(1)\r\n",
        "model.drop_rate=0.5\r\n",
        "\r\n",
        "model=model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYfLJwrX_N-c",
        "outputId": "fd88c5e8-40ad-4831-8664-61c6c3d8715f"
      },
      "source": [
        "\r\n",
        "a=torch.Tensor(1,3,224,224).to(device)\r\n",
        "out = model(a)\r\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0563]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zQxoi3q0YuM",
        "outputId": "df9c2a15-b2e2-4cf6-d27c-4063ada12b16"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bHWohMd0a3Q"
      },
      "source": [
        "PATH='/content/gdrive/MyDrive/Colab Notebooks/jaundice/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVgcBJrO0ckc"
      },
      "source": [
        "class CustomDataset(Dataset): \r\n",
        "  def __init__(self,x,y):\r\n",
        "    #self.transform=transform\r\n",
        "    self.x_0_data = x[:,:,0:112,:]\r\n",
        "    \r\n",
        "    self.x_1_data=x[:,:,112:,:]\r\n",
        "    self.y_data = y\r\n",
        "\r\n",
        "  # 총 데이터의 개수를 리턴\r\n",
        "  def __len__(self): \r\n",
        "    return len(self.y_data)\r\n",
        "\r\n",
        "  # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\r\n",
        "  def __getitem__(self, idx): \r\n",
        "    \r\n",
        "    #x_0=pilimg.fromarray(self.x_0_data[idx].astype(np.uint8))\r\n",
        "    #x_0=self.transform(x_0)\r\n",
        "    x_0 = torch.FloatTensor(self.x_0_data[idx])\r\n",
        "    #x_0=F.interpolate(x_0,size=(224,224),mode='bilinear',align_corners=False)\r\n",
        "    x_1= torch.FloatTensor(self.x_1_data[idx])\r\n",
        "    #x_1=F.interpolate(x_1,size=(224,224),mode='bilinear',align_corners=False)\r\n",
        "    y = torch.FloatTensor(self.y_data[idx])\r\n",
        "    return x_0,x_1, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8yUJ5EmDrBK"
      },
      "source": [
        "trainset=torch.load(PATH+'normsplitjaundicetrainset.csv')\r\n",
        "testset=torch.load(PATH+'normsplitjaundicetestset.csv')\r\n",
        "\r\n",
        "\r\n",
        "trainbatchsize=8\r\n",
        "testbatchsize=1\r\n",
        "trainloader=torch.utils.data.DataLoader(trainset,batch_size=trainbatchsize,shuffle=True,num_workers=4,drop_last=True)\r\n",
        "testloader=torch.utils.data.DataLoader(testset,batch_size=testbatchsize,shuffle=False,num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7QKuc3jCKhc"
      },
      "source": [
        "zt=torch.zeros((1,3,224,224)).to(device)\r\n",
        "for i, data in enumerate(testloader, 0):\r\n",
        "    # get the inputs\r\n",
        "    inputs_0,inputs_1, labels = data\r\n",
        "    zt[:,:,0:112,:] = inputs_0.to(device)\r\n",
        "    zt[:,:,112:,:] = inputs_1.to(device)\r\n",
        "    zt=zt.cpu()\r\n",
        "    plt.imshow(zt[0].permute(1, 2, 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EMJp6wewkvW"
      },
      "source": [
        "***Patch or not***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmidF2anu0C_"
      },
      "source": [
        "experiment='withoutpatch'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZsMMW4GX_b4"
      },
      "source": [
        "***binary classification training***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVqkEMpZ0uAw",
        "outputId": "60ffc670-c37f-426f-b7e9-4493a3daa369"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\r\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\r\n",
        "optimizer=adabelief_pytorch.AdaBelief(model.parameters(),lr=0.001)\r\n",
        "#lr_sche = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\r\n",
        "\r\n",
        "sig=nn.Sigmoid()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "Rectification enabled in AdaBelief\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgXCpDAM0yo1"
      },
      "source": [
        "trainedepochs=0\r\n",
        "print(len(trainloader))\r\n",
        "\r\n",
        "epochs = 20\r\n",
        "z=torch.zeros((trainbatchsize,3,224,224)).to(device)\r\n",
        "outarr=np.zeros(len(testloader))\r\n",
        "labarr=np.zeros(len(testloader))\r\n",
        "\r\n",
        "for epoch in range(epochs):\r\n",
        "  model.train()\r\n",
        "  \r\n",
        "  running_loss = 0.0\r\n",
        "\r\n",
        "  for i, data in enumerate(trainloader, 0):\r\n",
        "    # get the inputs\r\n",
        "    inputs_0,inputs_1, labels = data\r\n",
        "    z[:,:,0:112,:] = inputs_0.to(device)\r\n",
        "    z[:,:,112:,:] = inputs_1.to(device)\r\n",
        "\r\n",
        "    labels = labels.to(device)\r\n",
        "\r\n",
        "    # zero the parameter gradients\r\n",
        "    optimizer.zero_grad()\r\n",
        "\r\n",
        "    # forward + backward + optimize\r\n",
        "    outputs = model(z)\r\n",
        "\r\n",
        "    labels=labels.to(torch.float)/10\r\n",
        "    \r\n",
        "    for j in range(len(labels)):\r\n",
        "      if (labels[j][0]<1.3):\r\n",
        "        labels[j][0]=0\r\n",
        "      else: \r\n",
        "        labels[j][0]=1\r\n",
        " \r\n",
        "       # (numarray.max()/numarray[labels[0][0].to(torch.int).tolist()-1])\r\n",
        "    #loss = (1/numnum[labels[0][0].to(torch.int).tolist()-1])*criterion(outputs, labels.to(torch.float)/10)\r\n",
        "    loss = criterion(outputs, labels)\r\n",
        "    \r\n",
        "    #print( (numnum.max()/numnum[labels[0][0].to(torch.int).tolist()-1]))\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "        # print statistics\r\n",
        "    running_loss += loss.item()\r\n",
        "    if i % 20 == 19:    \r\n",
        "      print('[%d, %5d] loss: %.3f' %\r\n",
        "            (epoch + 1, i + 1, running_loss / 20))\r\n",
        "      running_loss = 0.0\r\n",
        "    #lr_sche.step()\r\n",
        "  \r\n",
        "  \r\n",
        "  if (epoch%5==4):\r\n",
        "    model.eval()\r\n",
        "    \r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "      for i, data in enumerate(testloader, 0):\r\n",
        "        inputs_0,inputs_1, labels = data\r\n",
        "        z[:,:,0:112,:] = inputs_0.to(device)\r\n",
        "        z[:,:,112:,:] = inputs_1.to(device)\r\n",
        "        labels = labels.to(device)\r\n",
        "        # zeo the parameter gradients\r\n",
        "        # forward + backward + optimize\r\n",
        "        outputs = model(z)\r\n",
        "        labels=labels.to(torch.float)/10\r\n",
        "\r\n",
        "        \r\n",
        "\r\n",
        "        for j in range(len(labels)):\r\n",
        "          if (labels[j][0]<1.3):\r\n",
        "            labels[j][0]=0\r\n",
        "          else: \r\n",
        "            labels[j][0]=1\r\n",
        " \r\n",
        "        \r\n",
        "        outarr[i]=sig(outputs[0][0]).cpu().numpy()\r\n",
        "        labarr[i]=(labels[0][0].cpu().numpy())\r\n",
        "      #print(labarr,outarr)\r\n",
        "      print(roc_auc_score(labarr,outarr))\r\n",
        "\r\n",
        "\r\n",
        "        \r\n",
        "\r\n",
        "\r\n",
        "  if (epoch==50 or epoch==100 or epoch==150 or epoch==200 or epoch==250 or epoch==300 or epoch==350 or epoch==400 or epoch==450 or epoch==500 or epoch==550):\r\n",
        "    torch.save(model.state_dict,PATH+'efficientnetb0test/'+experiment+'binmodel{}.pt'.format(trainedepochs+epoch))  \r\n",
        "    if (epoch==100 or epoch==200 or epoch==300 or  epoch==400 or epoch==500 ):\r\n",
        "      torch.save(optimizer.state_dict, PATH+'efficientnetb0test/'+experiment+'binoptimizer{}.pt'.format(trainedepochs+epoch))\r\n",
        "\r\n",
        "        \r\n",
        "        \r\n",
        "      \r\n",
        "      # loop over the dataset multiple times\r\n",
        "\r\n",
        "    #Check Accuracy\r\n",
        "    #acc = acc_check(resnet50, testloader, epoch, save=1)\r\n",
        "    \r\n",
        "    \r\n",
        "torch.save(model.state_dict,PATH+'efficientnetb0test/'+experiment+'binmodel{}.pt'.format(trainedepochs+epochs))\r\n",
        "torch.save(optimizer.state_dict, PATH+'efficientnetb0test/'+experiment+'binoptimizer{}.pt'.format(trainedepochs+epochs))\r\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJOrsoiKs3hI"
      },
      "source": [
        "***regression training***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLxhm377qxNf",
        "outputId": "18aef722-8cc0-4b36-9ab1-e6d325aff6ee"
      },
      "source": [
        "len(trainset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1034"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56fxWjGVrBXX"
      },
      "source": [
        "numset=torch.zeros((224,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGmN7UxVrZxN"
      },
      "source": [
        "\n",
        "for j in range(len(numset)):\n",
        "  cnt=0\n",
        "  for i in range(len(trainset)):\n",
        "    _,_,num=trainset[i]\n",
        "    \n",
        "    if num==j+1:\n",
        "      cnt=cnt+1\n",
        "\n",
        "  numset[j]=cnt   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5EQRcSMznRR"
      },
      "source": [
        "torch.save(numset, PATH+'nunmset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eay8bRZZmpHg"
      },
      "source": [
        "numset=torch.load(PATH+'nunmset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLur1dtlzZLk",
        "outputId": "af593b27-f092-40f0-d88c-e9d21f6dbbf3"
      },
      "source": [
        "int(numset[1])/10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kx0yEKXbYNqZ",
        "outputId": "6ab8bdc4-d0c6-49fa-b19b-025519aec655"
      },
      "source": [
        "#criterion=custom_loss()\r\n",
        "optimizer=adabelief_pytorch.AdaBelief(model.parameters(),lr=0.001)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "Rectification enabled in AdaBelief\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnbfXz-T1two"
      },
      "source": [
        "\n",
        "def mse_loss(\n",
        "    input: Tensor,\n",
        "    target: Tensor,\n",
        "    size_average: Optional[bool] = None,\n",
        "    reduce: Optional[bool] = None,\n",
        "    reduction: str = \"mean\",\n",
        ") -> Tensor:\n",
        "    r\"\"\"mse_loss(input, target, size_average=None, reduce=None, reduction='mean') -> Tensor\n",
        "\n",
        "    Measures the element-wise mean squared error.\n",
        "\n",
        "    See :class:`~torch.nn.MSELoss` for details.\n",
        "    \"\"\"\n",
        "    if has_torch_function_variadic(input, target):\n",
        "        return handle_torch_function(\n",
        "            mse_loss, (input, target), input, target, size_average=size_average, reduce=reduce, reduction=reduction\n",
        "        )\n",
        "    if not (target.size() == input.size()):\n",
        "        warnings.warn(\n",
        "            \"Using a target size ({}) that is different to the input size ({}). \"\n",
        "            \"This will likely lead to incorrect results due to broadcasting. \"\n",
        "            \"Please ensure they have the same size.\".format(target.size(), input.size()),\n",
        "            stacklevel=2,\n",
        "        )\n",
        "    if size_average is not None or reduce is not None:\n",
        "        reduction = _Reduction.legacy_get_string(size_average, reduce)\n",
        "\n",
        "    expanded_input, expanded_target = torch.broadcast_tensors(input, target)\n",
        "    return torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKY8Sddu09QG"
      },
      "source": [
        "class customMSELoss(_Loss):\n",
        "  def __init__(self, size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
        "        super(customMSELoss, self).__init__(size_average, reduce, reduction)\n",
        "\n",
        "  def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
        "        \n",
        "        return mse_loss(input, target, reduction=self.reduction)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h0rdV9tlfkP"
      },
      "source": [
        "_,_,lab=trainset[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jtkrMDjlkJ3",
        "outputId": "3f4ce7ca-960a-41d4-b5a3-0be0e17d85a2"
      },
      "source": [
        "int(lab[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q95sFA9jVeG"
      },
      "source": [
        "def custom_loss(output, target, numset):\n",
        "  batchsize=len(output)\n",
        "  \n",
        "  inloss=torch.empty(batchsize)\n",
        "\n",
        "  for i in range(batchsize):\n",
        "    inloss[i]=torch.square(output[i]-target[i]/10)\n",
        "    inloss[i]=inloss[i]*(torch.pow((numset[int(target[i][0])-1]),-1))\n",
        "  \n",
        "  \n",
        "\n",
        "  loss=torch.mean(inloss)\n",
        "  \n",
        "  return loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf_XkLdEntw0"
      },
      "source": [
        "class weightMSELoss(nn.Module):\n",
        "  def forward(self,input,target,numset):\n",
        "    return custom_loss(input,target,numset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhlAHx-ao90B"
      },
      "source": [
        "criterion=weightMSELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8-xluO4uJZk",
        "outputId": "3c6f52a7-0758-4aba-d873-e00d70725604"
      },
      "source": [
        "\n",
        "print(len(trainloader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "103\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aHiOB4GxPiGT",
        "outputId": "07c3bb5b-d119-4f56-d7dc-2bcf97515bab"
      },
      "source": [
        "trainedepochs=0\r\n",
        "print(len(trainloader))\r\n",
        "\r\n",
        "epochs = 400\r\n",
        "z=torch.zeros((trainbatchsize,3,224,224)).to(device)\r\n",
        "zt=torch.zeros((testbatchsize,3,224,224)).to(device)\r\n",
        "outarr=np.zeros(len(testloader))\r\n",
        "labarr=np.zeros(len(testloader))\r\n",
        "\r\n",
        "for epoch in range(epochs):\r\n",
        "  model.train()\r\n",
        "  \r\n",
        "  running_loss = 0.0\r\n",
        "\r\n",
        "  for i, data in enumerate(trainloader, 0):\r\n",
        "    # get the inputs\r\n",
        "    inputs_0,inputs_1, labels = data\r\n",
        "    \r\n",
        "    z[:,:,0:112,:] = inputs_0.to(device)\r\n",
        "    z[:,:,112:,:] = inputs_1.to(device)\r\n",
        "\r\n",
        "    labels = labels.to(device)\r\n",
        "\r\n",
        "    # zero the parameter gradients\r\n",
        "    optimizer.zero_grad()\r\n",
        "\r\n",
        "    # forward + backward + optimize\r\n",
        "    outputs = model(z)\r\n",
        "\r\n",
        "    labels=labels.to(torch.float)\r\n",
        "    '''\r\n",
        "    for j in range(len(labels)):\r\n",
        "      if (labels[j][0]<1.3):\r\n",
        "        labels[j][0]=0\r\n",
        "      else: \r\n",
        "        labels[j][0]=1\r\n",
        "    '''\r\n",
        "       # (numarray.max()/numarray[labels[0][0].to(torch.int).tolist()-1])\r\n",
        "    #loss = (1/numnum[labels[0][0].to(torch.int).tolist()-1])*criterion(outputs, labels.to(torch.float)/10)\r\n",
        "    loss = criterion(outputs, labels,numset)\r\n",
        "    #loss=custom_loss(outputs,labels,numset)\r\n",
        "    #print( (numnum.max()/numnum[labels[0][0].to(torch.int).tolist()-1]))\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "        # print statistics\r\n",
        "    running_loss += loss.item()\r\n",
        "    if i % 20 == 19:    \r\n",
        "      print('[%d, %5d] loss: %.3f' %\r\n",
        "            (epoch + 1, i + 1, running_loss / 20))\r\n",
        "      running_loss = 0.0\r\n",
        "    #lr_sche.step()\r\n",
        "  \r\n",
        "  \r\n",
        "  if (epoch%4==3):\r\n",
        "    model.eval()\r\n",
        "    \r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "      for i, data in enumerate(testloader, 0):\r\n",
        "        inputs_0,inputs_1, labels = data\r\n",
        "        zt[:,:,0:112,:] = inputs_0.to(device)\r\n",
        "        zt[:,:,112:,:] = inputs_1.to(device)\r\n",
        "        labels = labels.to(device)\r\n",
        "        # zeo the parameter gradients\r\n",
        "        # forward + backward + optimize\r\n",
        "        outputs = model(zt)\r\n",
        "        labels=labels.to(torch.float)/10\r\n",
        "\r\n",
        "        \r\n",
        "        '''\r\n",
        "        for j in range(len(labels)):\r\n",
        "          if (labels[j][0]<1.3):\r\n",
        "            labels[j][0]=0\r\n",
        "          else: \r\n",
        "            labels[j][0]=1\r\n",
        "        '''\r\n",
        "        \r\n",
        "        outarr[i]=outputs[0][0].cpu().numpy()\r\n",
        "        labarr[i]=(labels[0][0].cpu().numpy())\r\n",
        "        \r\n",
        "      \r\n",
        "      #print(labarr,outarr)\r\n",
        "      np.savetxt(PATH+'batsize{}_{}_pred{}_norm_nopatch_b0.txt'.format(trainbatchsize,np.corrcoef(labarr,outarr)[0][1],epoch+trainedepochs),outarr)\r\n",
        "      np.savetxt(PATH+'lab.txt',labarr)\r\n",
        "      print(np.corrcoef(labarr,outarr)[0][1])\r\n",
        "      print(stats.spearmanr(labarr,outarr))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "        \r\n",
        "\r\n",
        "  '''\r\n",
        "  if (epoch==50 or epoch==100 or epoch==150 or epoch==200 or epoch==250 or epoch==300 or epoch==350 or epoch==400 or epoch==450 or epoch==500 or epoch==550):\r\n",
        "    torch.save(model.state_dict,PATH+'efficientnetb0test/'+experiment+'regmodel{}.pt'.format(trainedepochs+epoch))  \r\n",
        "    if (epoch==100 or epoch==200 or epoch==300 or  epoch==400 or epoch==500 ):\r\n",
        "      torch.save(optimizer.state_dict, PATH+'efficientnetb0test/'+experiment+'regoptimizer{}.pt'.format(trainedepochs+epoch))\r\n",
        "  '''\r\n",
        "        \r\n",
        "        \r\n",
        "      \r\n",
        "      # loop over the dataset multiple times\r\n",
        "\r\n",
        "    #Check Accuracy\r\n",
        "    #acc = acc_check(resnet50, testloader, epoch, save=1)\r\n",
        "    \r\n",
        "'''  \r\n",
        "torch.save(model.state_dict,PATH+'efficientnetb0test/'+experiment+'regmodel{}.pt'.format(trainedepochs+epochs))\r\n",
        "torch.save(optimizer.state_dict, PATH+'efficientnetb0test/'+experiment+'regoptimizer{}.pt'.format(trainedepochs+epochs))\r\n",
        "print('Finished Training')\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "129\n",
            "[1,    20] loss: 3.164\n",
            "[1,    40] loss: 2.147\n",
            "[1,    60] loss: 1.889\n",
            "[1,    80] loss: 0.831\n",
            "[1,   100] loss: 4.023\n",
            "[1,   120] loss: 1.706\n",
            "[2,    20] loss: 0.771\n",
            "[2,    40] loss: 0.885\n",
            "[2,    60] loss: 1.302\n",
            "[2,    80] loss: 0.992\n",
            "[2,   100] loss: 1.005\n",
            "[2,   120] loss: 1.131\n",
            "[3,    20] loss: 0.637\n",
            "[3,    40] loss: 1.045\n",
            "[3,    60] loss: 0.510\n",
            "[3,    80] loss: 0.730\n",
            "[3,   100] loss: 1.371\n",
            "[3,   120] loss: 1.206\n",
            "[4,    20] loss: 0.521\n",
            "[4,    40] loss: 1.554\n",
            "[4,    60] loss: 0.620\n",
            "[4,    80] loss: 0.650\n",
            "[4,   100] loss: 1.752\n",
            "[4,   120] loss: 0.571\n",
            "0.8647115089476058\n",
            "SpearmanrResult(correlation=0.49254755160373387, pvalue=1.7708112038293087e-27)\n",
            "[5,    20] loss: 0.428\n",
            "[5,    40] loss: 0.461\n",
            "[5,    60] loss: 1.025\n",
            "[5,    80] loss: 1.789\n",
            "[5,   100] loss: 0.979\n",
            "[5,   120] loss: 0.650\n",
            "[6,    20] loss: 0.427\n",
            "[6,    40] loss: 0.754\n",
            "[6,    60] loss: 0.578\n",
            "[6,    80] loss: 0.766\n",
            "[6,   100] loss: 1.209\n",
            "[6,   120] loss: 0.568\n",
            "[7,    20] loss: 1.325\n",
            "[7,    40] loss: 0.626\n",
            "[7,    60] loss: 0.419\n",
            "[7,    80] loss: 0.973\n",
            "[7,   100] loss: 0.635\n",
            "[7,   120] loss: 1.344\n",
            "[8,    20] loss: 0.616\n",
            "[8,    40] loss: 1.168\n",
            "[8,    60] loss: 0.454\n",
            "[8,    80] loss: 0.365\n",
            "[8,   100] loss: 0.342\n",
            "[8,   120] loss: 0.837\n",
            "0.3471460915859985\n",
            "SpearmanrResult(correlation=-0.06546957899839982, pvalue=0.17690523881248452)\n",
            "[9,    20] loss: 0.587\n",
            "[9,    40] loss: 0.296\n",
            "[9,    60] loss: 0.355\n",
            "[9,    80] loss: 0.837\n",
            "[9,   100] loss: 0.709\n",
            "[9,   120] loss: 1.127\n",
            "[10,    20] loss: 0.565\n",
            "[10,    40] loss: 0.605\n",
            "[10,    60] loss: 1.019\n",
            "[10,    80] loss: 0.769\n",
            "[10,   100] loss: 0.349\n",
            "[10,   120] loss: 0.357\n",
            "[11,    20] loss: 0.832\n",
            "[11,    40] loss: 0.422\n",
            "[11,    60] loss: 0.258\n",
            "[11,    80] loss: 0.411\n",
            "[11,   100] loss: 0.350\n",
            "[11,   120] loss: 0.368\n",
            "[12,    20] loss: 0.192\n",
            "[12,    40] loss: 0.590\n",
            "[12,    60] loss: 0.480\n",
            "[12,    80] loss: 0.187\n",
            "[12,   100] loss: 0.141\n",
            "[12,   120] loss: 0.277\n",
            "0.8147906908659573\n",
            "SpearmanrResult(correlation=0.3001851513733144, pvalue=2.4288467730029724e-10)\n",
            "[13,    20] loss: 0.117\n",
            "[13,    40] loss: 0.333\n",
            "[13,    60] loss: 0.267\n",
            "[13,    80] loss: 0.329\n",
            "[13,   100] loss: 0.202\n",
            "[13,   120] loss: 0.484\n",
            "[14,    20] loss: 0.290\n",
            "[14,    40] loss: 0.216\n",
            "[14,    60] loss: 0.197\n",
            "[14,    80] loss: 0.183\n",
            "[14,   100] loss: 0.608\n",
            "[14,   120] loss: 0.375\n",
            "[15,    20] loss: 0.488\n",
            "[15,    40] loss: 0.248\n",
            "[15,    60] loss: 0.220\n",
            "[15,    80] loss: 0.205\n",
            "[15,   100] loss: 0.296\n",
            "[15,   120] loss: 0.564\n",
            "[16,    20] loss: 0.322\n",
            "[16,    40] loss: 0.486\n",
            "[16,    60] loss: 0.838\n",
            "[16,    80] loss: 0.730\n",
            "[16,   100] loss: 0.343\n",
            "[16,   120] loss: 0.311\n",
            "0.8258856881774783\n",
            "SpearmanrResult(correlation=0.5751398484998964, pvalue=5.7315267385868006e-39)\n",
            "[17,    20] loss: 0.323\n",
            "[17,    40] loss: 0.240\n",
            "[17,    60] loss: 0.654\n",
            "[17,    80] loss: 1.287\n",
            "[17,   100] loss: 0.466\n",
            "[17,   120] loss: 0.532\n",
            "[18,    20] loss: 0.670\n",
            "[18,    40] loss: 0.223\n",
            "[18,    60] loss: 0.305\n",
            "[18,    80] loss: 0.184\n",
            "[18,   100] loss: 0.791\n",
            "[18,   120] loss: 0.534\n",
            "[19,    20] loss: 0.826\n",
            "[19,    40] loss: 1.189\n",
            "[19,    60] loss: 0.952\n",
            "[19,    80] loss: 0.574\n",
            "[19,   100] loss: 0.509\n",
            "[19,   120] loss: 0.482\n",
            "[20,    20] loss: 0.589\n",
            "[20,    40] loss: 0.513\n",
            "[20,    60] loss: 0.406\n",
            "[20,    80] loss: 0.502\n",
            "[20,   100] loss: 0.429\n",
            "[20,   120] loss: 0.558\n",
            "0.8369456779969617\n",
            "SpearmanrResult(correlation=0.28788508477913327, pvalue=1.359696877476466e-09)\n",
            "[21,    20] loss: 0.226\n",
            "[21,    40] loss: 0.576\n",
            "[21,    60] loss: 0.404\n",
            "[21,    80] loss: 0.248\n",
            "[21,   100] loss: 0.302\n",
            "[21,   120] loss: 0.363\n",
            "[22,    20] loss: 0.453\n",
            "[22,    40] loss: 0.762\n",
            "[22,    60] loss: 0.430\n",
            "[22,    80] loss: 0.277\n",
            "[22,   100] loss: 0.396\n",
            "[22,   120] loss: 0.228\n",
            "[23,    20] loss: 0.410\n",
            "[23,    40] loss: 0.533\n",
            "[23,    60] loss: 0.277\n",
            "[23,    80] loss: 0.263\n",
            "[23,   100] loss: 0.151\n",
            "[23,   120] loss: 0.129\n",
            "[24,    20] loss: 0.145\n",
            "[24,    40] loss: 0.253\n",
            "[24,    60] loss: 0.165\n",
            "[24,    80] loss: 0.559\n",
            "[24,   100] loss: 0.248\n",
            "[24,   120] loss: 0.237\n",
            "0.8138134942543044\n",
            "SpearmanrResult(correlation=0.4268256124463027, pvalue=2.4691237540743315e-20)\n",
            "[25,    20] loss: 0.198\n",
            "[25,    40] loss: 0.221\n",
            "[25,    60] loss: 0.380\n",
            "[25,    80] loss: 0.177\n",
            "[25,   100] loss: 0.462\n",
            "[25,   120] loss: 0.341\n",
            "[26,    20] loss: 0.471\n",
            "[26,    40] loss: 0.320\n",
            "[26,    60] loss: 0.133\n",
            "[26,    80] loss: 0.200\n",
            "[26,   100] loss: 0.213\n",
            "[26,   120] loss: 0.139\n",
            "[27,    20] loss: 0.131\n",
            "[27,    40] loss: 0.121\n",
            "[27,    60] loss: 0.205\n",
            "[27,    80] loss: 0.227\n",
            "[27,   100] loss: 0.206\n",
            "[27,   120] loss: 0.216\n",
            "[28,    20] loss: 0.511\n",
            "[28,    40] loss: 0.305\n",
            "[28,    60] loss: 0.138\n",
            "[28,    80] loss: 0.130\n",
            "[28,   100] loss: 0.410\n",
            "[28,   120] loss: 0.159\n",
            "0.8456621474097865\n",
            "SpearmanrResult(correlation=0.3889735969675292, pvalue=7.116364946532867e-17)\n",
            "[29,    20] loss: 0.169\n",
            "[29,    40] loss: 0.110\n",
            "[29,    60] loss: 0.156\n",
            "[29,    80] loss: 0.131\n",
            "[29,   100] loss: 0.090\n",
            "[29,   120] loss: 0.253\n",
            "[30,    20] loss: 0.115\n",
            "[30,    40] loss: 0.177\n",
            "[30,    60] loss: 0.118\n",
            "[30,    80] loss: 0.097\n",
            "[30,   100] loss: 0.225\n",
            "[30,   120] loss: 0.163\n",
            "[31,    20] loss: 0.166\n",
            "[31,    40] loss: 0.173\n",
            "[31,    60] loss: 0.284\n",
            "[31,    80] loss: 0.162\n",
            "[31,   100] loss: 0.096\n",
            "[31,   120] loss: 0.180\n",
            "[32,    20] loss: 0.168\n",
            "[32,    40] loss: 0.150\n",
            "[32,    60] loss: 0.217\n",
            "[32,    80] loss: 0.094\n",
            "[32,   100] loss: 0.144\n",
            "[32,   120] loss: 0.226\n",
            "0.8438640774691188\n",
            "SpearmanrResult(correlation=0.497644886937164, pvalue=4.233645891113698e-28)\n",
            "[33,    20] loss: 0.122\n",
            "[33,    40] loss: 0.110\n",
            "[33,    60] loss: 0.073\n",
            "[33,    80] loss: 0.078\n",
            "[33,   100] loss: 0.085\n",
            "[33,   120] loss: 0.320\n",
            "[34,    20] loss: 0.150\n",
            "[34,    40] loss: 0.086\n",
            "[34,    60] loss: 0.119\n",
            "[34,    80] loss: 0.169\n",
            "[34,   100] loss: 0.083\n",
            "[34,   120] loss: 0.088\n",
            "[35,    20] loss: 0.106\n",
            "[35,    40] loss: 0.075\n",
            "[35,    60] loss: 0.124\n",
            "[35,    80] loss: 0.218\n",
            "[35,   100] loss: 0.146\n",
            "[35,   120] loss: 0.097\n",
            "[36,    20] loss: 0.132\n",
            "[36,    40] loss: 0.087\n",
            "[36,    60] loss: 0.150\n",
            "[36,    80] loss: 0.100\n",
            "[36,   100] loss: 0.098\n",
            "[36,   120] loss: 0.070\n",
            "0.8951395123458021\n",
            "SpearmanrResult(correlation=0.49335615464773136, pvalue=1.4134611603259288e-27)\n",
            "[37,    20] loss: 0.081\n",
            "[37,    40] loss: 0.180\n",
            "[37,    60] loss: 0.063\n",
            "[37,    80] loss: 0.073\n",
            "[37,   100] loss: 0.092\n",
            "[37,   120] loss: 0.114\n",
            "[38,    20] loss: 0.087\n",
            "[38,    40] loss: 0.116\n",
            "[38,    60] loss: 0.110\n",
            "[38,    80] loss: 0.049\n",
            "[38,   100] loss: 0.082\n",
            "[38,   120] loss: 0.061\n",
            "[39,    20] loss: 0.239\n",
            "[39,    40] loss: 0.168\n",
            "[39,    60] loss: 0.211\n",
            "[39,    80] loss: 0.120\n",
            "[39,   100] loss: 0.169\n",
            "[39,   120] loss: 0.141\n",
            "[40,    20] loss: 0.073\n",
            "[40,    40] loss: 0.263\n",
            "[40,    60] loss: 0.203\n",
            "[40,    80] loss: 0.140\n",
            "[40,   100] loss: 0.104\n",
            "[40,   120] loss: 0.109\n",
            "0.8409137513219167\n",
            "SpearmanrResult(correlation=0.5481033235833412, pvalue=7.49198969835591e-35)\n",
            "[41,    20] loss: 0.176\n",
            "[41,    40] loss: 0.173\n",
            "[41,    60] loss: 0.310\n",
            "[41,    80] loss: 0.449\n",
            "[41,   100] loss: 0.287\n",
            "[41,   120] loss: 1.541\n",
            "[42,    20] loss: 3.498\n",
            "[42,    40] loss: 1.519\n",
            "[42,    60] loss: 0.914\n",
            "[42,    80] loss: 1.040\n",
            "[42,   100] loss: 1.169\n",
            "[42,   120] loss: 2.014\n",
            "[43,    20] loss: 1.244\n",
            "[43,    40] loss: 0.899\n",
            "[43,    60] loss: 1.352\n",
            "[43,    80] loss: 1.057\n",
            "[43,   100] loss: 0.788\n",
            "[43,   120] loss: 0.510\n",
            "[44,    20] loss: 0.384\n",
            "[44,    40] loss: 1.638\n",
            "[44,    60] loss: 1.193\n",
            "[44,    80] loss: 0.979\n",
            "[44,   100] loss: 1.036\n",
            "[44,   120] loss: 0.717\n",
            "0.7621482207609835\n",
            "SpearmanrResult(correlation=0.1769954663592197, pvalue=0.00023713254884784538)\n",
            "[45,    20] loss: 1.356\n",
            "[45,    40] loss: 2.349\n",
            "[45,    60] loss: 0.981\n",
            "[45,    80] loss: 1.040\n",
            "[45,   100] loss: 0.918\n",
            "[45,   120] loss: 0.421\n",
            "[46,    20] loss: 0.689\n",
            "[46,    40] loss: 0.605\n",
            "[46,    60] loss: 0.399\n",
            "[46,    80] loss: 0.614\n",
            "[46,   100] loss: 1.008\n",
            "[46,   120] loss: 0.401\n",
            "[47,    20] loss: 0.592\n",
            "[47,    40] loss: 0.638\n",
            "[47,    60] loss: 0.599\n",
            "[47,    80] loss: 0.495\n",
            "[47,   100] loss: 0.500\n",
            "[47,   120] loss: 0.353\n",
            "[48,    20] loss: 0.371\n",
            "[48,    40] loss: 0.490\n",
            "[48,    60] loss: 0.390\n",
            "[48,    80] loss: 0.389\n",
            "[48,   100] loss: 0.783\n",
            "[48,   120] loss: 0.292\n",
            "0.7550471052421921\n",
            "SpearmanrResult(correlation=0.14444579504830218, pvalue=0.0027735615848560567)\n",
            "[49,    20] loss: 0.833\n",
            "[49,    40] loss: 0.753\n",
            "[49,    60] loss: 0.260\n",
            "[49,    80] loss: 0.401\n",
            "[49,   100] loss: 0.358\n",
            "[49,   120] loss: 0.398\n",
            "[50,    20] loss: 0.805\n",
            "[50,    40] loss: 0.912\n",
            "[50,    60] loss: 0.615\n",
            "[50,    80] loss: 0.324\n",
            "[50,   100] loss: 0.546\n",
            "[50,   120] loss: 0.388\n",
            "[51,    20] loss: 0.750\n",
            "[51,    40] loss: 0.406\n",
            "[51,    60] loss: 0.405\n",
            "[51,    80] loss: 0.294\n",
            "[51,   100] loss: 0.289\n",
            "[51,   120] loss: 0.254\n",
            "[52,    20] loss: 0.276\n",
            "[52,    40] loss: 0.333\n",
            "[52,    60] loss: 0.350\n",
            "[52,    80] loss: 0.279\n",
            "[52,   100] loss: 0.339\n",
            "[52,   120] loss: 0.224\n",
            "0.8541416937123644\n",
            "SpearmanrResult(correlation=0.4701361619434254, pvalue=7.2467616688333605e-25)\n",
            "[53,    20] loss: 0.139\n",
            "[53,    40] loss: 0.865\n",
            "[53,    60] loss: 0.281\n",
            "[53,    80] loss: 0.431\n",
            "[53,   100] loss: 0.153\n",
            "[53,   120] loss: 0.264\n",
            "[54,    20] loss: 0.296\n",
            "[54,    40] loss: 0.236\n",
            "[54,    60] loss: 0.229\n",
            "[54,    80] loss: 0.263\n",
            "[54,   100] loss: 0.364\n",
            "[54,   120] loss: 0.354\n",
            "[55,    20] loss: 0.369\n",
            "[55,    40] loss: 0.150\n",
            "[55,    60] loss: 0.119\n",
            "[55,    80] loss: 0.180\n",
            "[55,   100] loss: 0.161\n",
            "[55,   120] loss: 0.362\n",
            "[56,    20] loss: 0.174\n",
            "[56,    40] loss: 0.218\n",
            "[56,    60] loss: 0.287\n",
            "[56,    80] loss: 0.200\n",
            "[56,   100] loss: 0.184\n",
            "[56,   120] loss: 0.124\n",
            "0.8773061410308904\n",
            "SpearmanrResult(correlation=0.43999136630778224, pvalue=1.2099356856150581e-21)\n",
            "[57,    20] loss: 0.245\n",
            "[57,    40] loss: 0.290\n",
            "[57,    60] loss: 0.104\n",
            "[57,    80] loss: 0.160\n",
            "[57,   100] loss: 0.278\n",
            "[57,   120] loss: 0.229\n",
            "[58,    20] loss: 0.383\n",
            "[58,    40] loss: 0.281\n",
            "[58,    60] loss: 0.266\n",
            "[58,    80] loss: 0.118\n",
            "[58,   100] loss: 0.177\n",
            "[58,   120] loss: 0.127\n",
            "[59,    20] loss: 0.235\n",
            "[59,    40] loss: 0.124\n",
            "[59,    60] loss: 0.127\n",
            "[59,    80] loss: 0.117\n",
            "[59,   100] loss: 0.147\n",
            "[59,   120] loss: 0.091\n",
            "[60,    20] loss: 0.167\n",
            "[60,    40] loss: 0.185\n",
            "[60,    60] loss: 0.285\n",
            "[60,    80] loss: 0.165\n",
            "[60,   100] loss: 0.222\n",
            "[60,   120] loss: 0.139\n",
            "0.9078172758806096\n",
            "SpearmanrResult(correlation=0.6451083440524136, pvalue=1.297566080070326e-51)\n",
            "[61,    20] loss: 0.112\n",
            "[61,    40] loss: 0.159\n",
            "[61,    60] loss: 0.418\n",
            "[61,    80] loss: 0.284\n",
            "[61,   100] loss: 0.407\n",
            "[61,   120] loss: 0.169\n",
            "[62,    20] loss: 0.353\n",
            "[62,    40] loss: 0.276\n",
            "[62,    60] loss: 0.172\n",
            "[62,    80] loss: 0.186\n",
            "[62,   100] loss: 0.140\n",
            "[62,   120] loss: 0.185\n",
            "[63,    20] loss: 0.417\n",
            "[63,    40] loss: 0.372\n",
            "[63,    60] loss: 0.163\n",
            "[63,    80] loss: 0.296\n",
            "[63,   100] loss: 0.311\n",
            "[63,   120] loss: 0.125\n",
            "[64,    20] loss: 0.076\n",
            "[64,    40] loss: 0.311\n",
            "[64,    60] loss: 0.117\n",
            "[64,    80] loss: 0.118\n",
            "[64,   100] loss: 0.142\n",
            "[64,   120] loss: 0.134\n",
            "0.875347089990714\n",
            "SpearmanrResult(correlation=0.39960238581429647, pvalue=8.412719153341097e-18)\n",
            "[65,    20] loss: 0.142\n",
            "[65,    40] loss: 0.119\n",
            "[65,    60] loss: 0.101\n",
            "[65,    80] loss: 0.094\n",
            "[65,   100] loss: 0.100\n",
            "[65,   120] loss: 0.119\n",
            "[66,    20] loss: 0.075\n",
            "[66,    40] loss: 0.081\n",
            "[66,    60] loss: 0.088\n",
            "[66,    80] loss: 0.051\n",
            "[66,   100] loss: 0.076\n",
            "[66,   120] loss: 0.074\n",
            "[67,    20] loss: 0.302\n",
            "[67,    40] loss: 0.181\n",
            "[67,    60] loss: 0.148\n",
            "[67,    80] loss: 0.184\n",
            "[67,   100] loss: 0.163\n",
            "[67,   120] loss: 0.197\n",
            "[68,    20] loss: 0.194\n",
            "[68,    40] loss: 0.095\n",
            "[68,    60] loss: 0.139\n",
            "[68,    80] loss: 0.176\n",
            "[68,   100] loss: 0.325\n",
            "[68,   120] loss: 0.120\n",
            "0.8903302534122957\n",
            "SpearmanrResult(correlation=0.48225022202920514, pvalue=2.9664072273410503e-26)\n",
            "[69,    20] loss: 0.795\n",
            "[69,    40] loss: 0.238\n",
            "[69,    60] loss: 0.268\n",
            "[69,    80] loss: 0.205\n",
            "[69,   100] loss: 0.118\n",
            "[69,   120] loss: 0.278\n",
            "[70,    20] loss: 0.318\n",
            "[70,    40] loss: 0.472\n",
            "[70,    60] loss: 0.273\n",
            "[70,    80] loss: 0.115\n",
            "[70,   100] loss: 0.257\n",
            "[70,   120] loss: 0.115\n",
            "[71,    20] loss: 0.268\n",
            "[71,    40] loss: 0.156\n",
            "[71,    60] loss: 0.234\n",
            "[71,    80] loss: 0.141\n",
            "[71,   100] loss: 0.106\n",
            "[71,   120] loss: 0.115\n",
            "[72,    20] loss: 0.069\n",
            "[72,    40] loss: 0.126\n",
            "[72,    60] loss: 0.208\n",
            "[72,    80] loss: 0.080\n",
            "[72,   100] loss: 0.336\n",
            "[72,   120] loss: 0.155\n",
            "0.8992958964373184\n",
            "SpearmanrResult(correlation=0.5440829412150823, pvalue=2.8522541033445834e-34)\n",
            "[73,    20] loss: 0.095\n",
            "[73,    40] loss: 0.189\n",
            "[73,    60] loss: 0.161\n",
            "[73,    80] loss: 0.119\n",
            "[73,   100] loss: 0.381\n",
            "[73,   120] loss: 0.185\n",
            "[74,    20] loss: 0.525\n",
            "[74,    40] loss: 0.231\n",
            "[74,    60] loss: 0.089\n",
            "[74,    80] loss: 0.203\n",
            "[74,   100] loss: 0.115\n",
            "[74,   120] loss: 0.076\n",
            "[75,    20] loss: 0.076\n",
            "[75,    40] loss: 0.062\n",
            "[75,    60] loss: 0.043\n",
            "[75,    80] loss: 0.095\n",
            "[75,   100] loss: 0.109\n",
            "[75,   120] loss: 0.081\n",
            "[76,    20] loss: 0.102\n",
            "[76,    40] loss: 0.109\n",
            "[76,    60] loss: 0.127\n",
            "[76,    80] loss: 0.072\n",
            "[76,   100] loss: 0.060\n",
            "[76,   120] loss: 0.254\n",
            "0.8673724076514202\n",
            "SpearmanrResult(correlation=0.6585350322932035, pvalue=1.973052923217052e-54)\n",
            "[77,    20] loss: 0.121\n",
            "[77,    40] loss: 0.086\n",
            "[77,    60] loss: 0.062\n",
            "[77,    80] loss: 0.097\n",
            "[77,   100] loss: 0.174\n",
            "[77,   120] loss: 0.109\n",
            "[78,    20] loss: 0.047\n",
            "[78,    40] loss: 0.120\n",
            "[78,    60] loss: 0.070\n",
            "[78,    80] loss: 0.079\n",
            "[78,   100] loss: 0.110\n",
            "[78,   120] loss: 0.303\n",
            "[79,    20] loss: 0.091\n",
            "[79,    40] loss: 0.090\n",
            "[79,    60] loss: 0.106\n",
            "[79,    80] loss: 0.140\n",
            "[79,   100] loss: 0.056\n",
            "[79,   120] loss: 0.068\n",
            "[80,    20] loss: 0.092\n",
            "[80,    40] loss: 0.314\n",
            "[80,    60] loss: 0.715\n",
            "[80,    80] loss: 0.350\n",
            "[80,   100] loss: 0.229\n",
            "[80,   120] loss: 0.242\n",
            "0.8849703583395968\n",
            "SpearmanrResult(correlation=0.4862027058422794, pvalue=1.0169328997128834e-26)\n",
            "[81,    20] loss: 0.283\n",
            "[81,    40] loss: 0.556\n",
            "[81,    60] loss: 0.129\n",
            "[81,    80] loss: 0.113\n",
            "[81,   100] loss: 0.166\n",
            "[81,   120] loss: 0.208\n",
            "[82,    20] loss: 0.200\n",
            "[82,    40] loss: 0.190\n",
            "[82,    60] loss: 0.110\n",
            "[82,    80] loss: 0.068\n",
            "[82,   100] loss: 0.123\n",
            "[82,   120] loss: 0.087\n",
            "[83,    20] loss: 0.139\n",
            "[83,    40] loss: 0.073\n",
            "[83,    60] loss: 0.115\n",
            "[83,    80] loss: 0.062\n",
            "[83,   100] loss: 0.047\n",
            "[83,   120] loss: 0.175\n",
            "[84,    20] loss: 0.090\n",
            "[84,    40] loss: 0.145\n",
            "[84,    60] loss: 0.069\n",
            "[84,    80] loss: 0.064\n",
            "[84,   100] loss: 0.164\n",
            "[84,   120] loss: 0.093\n",
            "0.8935712026915923\n",
            "SpearmanrResult(correlation=0.5636790513051261, pvalue=3.5437128361968904e-37)\n",
            "[85,    20] loss: 0.084\n",
            "[85,    40] loss: 0.117\n",
            "[85,    60] loss: 0.077\n",
            "[85,    80] loss: 0.065\n",
            "[85,   100] loss: 0.060\n",
            "[85,   120] loss: 0.070\n",
            "[86,    20] loss: 0.120\n",
            "[86,    40] loss: 0.149\n",
            "[86,    60] loss: 0.184\n",
            "[86,    80] loss: 0.087\n",
            "[86,   100] loss: 0.051\n",
            "[86,   120] loss: 0.050\n",
            "[87,    20] loss: 0.048\n",
            "[87,    40] loss: 0.042\n",
            "[87,    60] loss: 0.126\n",
            "[87,    80] loss: 0.073\n",
            "[87,   100] loss: 0.064\n",
            "[87,   120] loss: 0.128\n",
            "[88,    20] loss: 0.068\n",
            "[88,    40] loss: 0.102\n",
            "[88,    60] loss: 0.092\n",
            "[88,    80] loss: 0.145\n",
            "[88,   100] loss: 0.153\n",
            "[88,   120] loss: 0.151\n",
            "0.8652974566949271\n",
            "SpearmanrResult(correlation=0.5421139603599529, pvalue=5.4536439419125755e-34)\n",
            "[89,    20] loss: 0.068\n",
            "[89,    40] loss: 0.085\n",
            "[89,    60] loss: 0.038\n",
            "[89,    80] loss: 0.062\n",
            "[89,   100] loss: 0.087\n",
            "[89,   120] loss: 0.068\n",
            "[90,    20] loss: 0.078\n",
            "[90,    40] loss: 0.041\n",
            "[90,    60] loss: 0.090\n",
            "[90,    80] loss: 0.047\n",
            "[90,   100] loss: 0.041\n",
            "[90,   120] loss: 0.080\n",
            "[91,    20] loss: 0.064\n",
            "[91,    40] loss: 0.134\n",
            "[91,    60] loss: 0.032\n",
            "[91,    80] loss: 0.126\n",
            "[91,   100] loss: 0.060\n",
            "[91,   120] loss: 0.030\n",
            "[92,    20] loss: 0.116\n",
            "[92,    40] loss: 0.139\n",
            "[92,    60] loss: 0.104\n",
            "[92,    80] loss: 0.057\n",
            "[92,   100] loss: 0.061\n",
            "[92,   120] loss: 0.052\n",
            "0.8956775182965522\n",
            "SpearmanrResult(correlation=0.649349338791102, pvalue=1.731536453258106e-52)\n",
            "[93,    20] loss: 0.075\n",
            "[93,    40] loss: 0.042\n",
            "[93,    60] loss: 0.052\n",
            "[93,    80] loss: 0.048\n",
            "[93,   100] loss: 0.123\n",
            "[93,   120] loss: 0.096\n",
            "[94,    20] loss: 0.069\n",
            "[94,    40] loss: 0.156\n",
            "[94,    60] loss: 0.112\n",
            "[94,    80] loss: 0.054\n",
            "[94,   100] loss: 0.068\n",
            "[94,   120] loss: 0.109\n",
            "[95,    20] loss: 0.192\n",
            "[95,    40] loss: 0.368\n",
            "[95,    60] loss: 0.129\n",
            "[95,    80] loss: 0.234\n",
            "[95,   100] loss: 0.233\n",
            "[95,   120] loss: 0.133\n",
            "[96,    20] loss: 0.171\n",
            "[96,    40] loss: 0.454\n",
            "[96,    60] loss: 0.438\n",
            "[96,    80] loss: 0.213\n",
            "[96,   100] loss: 0.152\n",
            "[96,   120] loss: 0.105\n",
            "0.8679900926543164\n",
            "SpearmanrResult(correlation=0.4899658616021593, pvalue=3.6221741461938104e-27)\n",
            "[97,    20] loss: 0.059\n",
            "[97,    40] loss: 0.073\n",
            "[97,    60] loss: 0.091\n",
            "[97,    80] loss: 0.095\n",
            "[97,   100] loss: 0.182\n",
            "[97,   120] loss: 0.160\n",
            "[98,    20] loss: 0.098\n",
            "[98,    40] loss: 0.174\n",
            "[98,    60] loss: 0.370\n",
            "[98,    80] loss: 0.077\n",
            "[98,   100] loss: 0.059\n",
            "[98,   120] loss: 0.065\n",
            "[99,    20] loss: 0.138\n",
            "[99,    40] loss: 0.150\n",
            "[99,    60] loss: 0.063\n",
            "[99,    80] loss: 0.174\n",
            "[99,   100] loss: 0.044\n",
            "[99,   120] loss: 0.076\n",
            "[100,    20] loss: 0.441\n",
            "[100,    40] loss: 0.211\n",
            "[100,    60] loss: 0.105\n",
            "[100,    80] loss: 0.104\n",
            "[100,   100] loss: 0.060\n",
            "[100,   120] loss: 0.080\n",
            "0.8964779245701664\n",
            "SpearmanrResult(correlation=0.6162852915086541, pvalue=5.1043140742535854e-46)\n",
            "[101,    20] loss: 0.061\n",
            "[101,    40] loss: 0.201\n",
            "[101,    60] loss: 0.105\n",
            "[101,    80] loss: 0.095\n",
            "[101,   100] loss: 0.083\n",
            "[101,   120] loss: 0.045\n",
            "[102,    20] loss: 0.089\n",
            "[102,    40] loss: 0.075\n",
            "[102,    60] loss: 0.061\n",
            "[102,    80] loss: 0.028\n",
            "[102,   100] loss: 0.360\n",
            "[102,   120] loss: 0.132\n",
            "[103,    20] loss: 0.125\n",
            "[103,    40] loss: 0.062\n",
            "[103,    60] loss: 0.108\n",
            "[103,    80] loss: 0.164\n",
            "[103,   100] loss: 0.066\n",
            "[103,   120] loss: 0.126\n",
            "[104,    20] loss: 0.091\n",
            "[104,    40] loss: 0.111\n",
            "[104,    60] loss: 0.044\n",
            "[104,    80] loss: 0.045\n",
            "[104,   100] loss: 0.051\n",
            "[104,   120] loss: 0.078\n",
            "0.9102529708616697\n",
            "SpearmanrResult(correlation=0.6442177065765545, pvalue=1.9727011287319316e-51)\n",
            "[105,    20] loss: 0.076\n",
            "[105,    40] loss: 0.031\n",
            "[105,    60] loss: 0.055\n",
            "[105,    80] loss: 0.072\n",
            "[105,   100] loss: 0.062\n",
            "[105,   120] loss: 0.076\n",
            "[106,    20] loss: 0.060\n",
            "[106,    40] loss: 0.149\n",
            "[106,    60] loss: 0.048\n",
            "[106,    80] loss: 0.108\n",
            "[106,   100] loss: 0.065\n",
            "[106,   120] loss: 0.054\n",
            "[107,    20] loss: 0.144\n",
            "[107,    40] loss: 0.076\n",
            "[107,    60] loss: 0.040\n",
            "[107,    80] loss: 0.061\n",
            "[107,   100] loss: 0.048\n",
            "[107,   120] loss: 0.040\n",
            "[108,    20] loss: 0.026\n",
            "[108,    40] loss: 0.068\n",
            "[108,    60] loss: 0.075\n",
            "[108,    80] loss: 0.051\n",
            "[108,   100] loss: 0.041\n",
            "[108,   120] loss: 0.064\n",
            "0.9141172768596793\n",
            "SpearmanrResult(correlation=0.6736512281551545, pvalue=8.791536184706808e-58)\n",
            "[109,    20] loss: 0.030\n",
            "[109,    40] loss: 0.023\n",
            "[109,    60] loss: 0.043\n",
            "[109,    80] loss: 0.110\n",
            "[109,   100] loss: 0.063\n",
            "[109,   120] loss: 0.056\n",
            "[110,    20] loss: 0.052\n",
            "[110,    40] loss: 0.090\n",
            "[110,    60] loss: 0.039\n",
            "[110,    80] loss: 0.052\n",
            "[110,   100] loss: 0.092\n",
            "[110,   120] loss: 0.063\n",
            "[111,    20] loss: 0.058\n",
            "[111,    40] loss: 0.047\n",
            "[111,    60] loss: 0.021\n",
            "[111,    80] loss: 0.040\n",
            "[111,   100] loss: 0.078\n",
            "[111,   120] loss: 0.040\n",
            "[112,    20] loss: 0.037\n",
            "[112,    40] loss: 0.033\n",
            "[112,    60] loss: 0.061\n",
            "[112,    80] loss: 0.100\n",
            "[112,   100] loss: 0.060\n",
            "[112,   120] loss: 0.041\n",
            "0.9090395518744245\n",
            "SpearmanrResult(correlation=0.6375256435164023, pvalue=4.394570802853735e-50)\n",
            "[113,    20] loss: 0.028\n",
            "[113,    40] loss: 0.040\n",
            "[113,    60] loss: 0.051\n",
            "[113,    80] loss: 0.094\n",
            "[113,   100] loss: 0.059\n",
            "[113,   120] loss: 0.113\n",
            "[114,    20] loss: 0.083\n",
            "[114,    40] loss: 0.036\n",
            "[114,    60] loss: 0.036\n",
            "[114,    80] loss: 0.038\n",
            "[114,   100] loss: 0.037\n",
            "[114,   120] loss: 0.039\n",
            "[115,    20] loss: 0.055\n",
            "[115,    40] loss: 0.046\n",
            "[115,    60] loss: 0.037\n",
            "[115,    80] loss: 0.048\n",
            "[115,   100] loss: 0.059\n",
            "[115,   120] loss: 0.066\n",
            "[116,    20] loss: 0.045\n",
            "[116,    40] loss: 0.049\n",
            "[116,    60] loss: 0.023\n",
            "[116,    80] loss: 0.048\n",
            "[116,   100] loss: 0.041\n",
            "[116,   120] loss: 0.024\n",
            "0.9178377662782419\n",
            "SpearmanrResult(correlation=0.6592629140742112, pvalue=1.3747484000505787e-54)\n",
            "[117,    20] loss: 0.031\n",
            "[117,    40] loss: 0.031\n",
            "[117,    60] loss: 0.039\n",
            "[117,    80] loss: 0.027\n",
            "[117,   100] loss: 0.032\n",
            "[117,   120] loss: 0.033\n",
            "[118,    20] loss: 0.161\n",
            "[118,    40] loss: 0.043\n",
            "[118,    60] loss: 0.097\n",
            "[118,    80] loss: 0.183\n",
            "[118,   100] loss: 0.069\n",
            "[118,   120] loss: 0.064\n",
            "[119,    20] loss: 0.119\n",
            "[119,    40] loss: 0.048\n",
            "[119,    60] loss: 0.055\n",
            "[119,    80] loss: 0.171\n",
            "[119,   100] loss: 0.091\n",
            "[119,   120] loss: 0.067\n",
            "[120,    20] loss: 0.138\n",
            "[120,    40] loss: 0.153\n",
            "[120,    60] loss: 0.175\n",
            "[120,    80] loss: 0.053\n",
            "[120,   100] loss: 0.066\n",
            "[120,   120] loss: 0.062\n",
            "0.8741546977260579\n",
            "SpearmanrResult(correlation=0.7152394408093262, pvalue=4.0091160771294745e-68)\n",
            "[121,    20] loss: 0.057\n",
            "[121,    40] loss: 0.248\n",
            "[121,    60] loss: 0.084\n",
            "[121,    80] loss: 0.052\n",
            "[121,   100] loss: 0.213\n",
            "[121,   120] loss: 0.096\n",
            "[122,    20] loss: 0.123\n",
            "[122,    40] loss: 0.069\n",
            "[122,    60] loss: 0.089\n",
            "[122,    80] loss: 0.049\n",
            "[122,   100] loss: 0.095\n",
            "[122,   120] loss: 0.036\n",
            "[123,    20] loss: 0.053\n",
            "[123,    40] loss: 0.105\n",
            "[123,    60] loss: 0.044\n",
            "[123,    80] loss: 0.047\n",
            "[123,   100] loss: 0.027\n",
            "[123,   120] loss: 0.031\n",
            "[124,    20] loss: 0.064\n",
            "[124,    40] loss: 0.059\n",
            "[124,    60] loss: 0.030\n",
            "[124,    80] loss: 0.049\n",
            "[124,   100] loss: 0.060\n",
            "[124,   120] loss: 0.088\n",
            "0.8864406819914893\n",
            "SpearmanrResult(correlation=0.5832037868047368, pvalue=2.8516261228009067e-40)\n",
            "[125,    20] loss: 0.074\n",
            "[125,    40] loss: 0.100\n",
            "[125,    60] loss: 0.068\n",
            "[125,    80] loss: 0.093\n",
            "[125,   100] loss: 0.036\n",
            "[125,   120] loss: 0.067\n",
            "[126,    20] loss: 0.048\n",
            "[126,    40] loss: 0.051\n",
            "[126,    60] loss: 0.053\n",
            "[126,    80] loss: 0.031\n",
            "[126,   100] loss: 0.031\n",
            "[126,   120] loss: 0.025\n",
            "[127,    20] loss: 0.028\n",
            "[127,    40] loss: 0.160\n",
            "[127,    60] loss: 0.134\n",
            "[127,    80] loss: 0.064\n",
            "[127,   100] loss: 0.093\n",
            "[127,   120] loss: 0.046\n",
            "[128,    20] loss: 0.084\n",
            "[128,    40] loss: 0.113\n",
            "[128,    60] loss: 0.042\n",
            "[128,    80] loss: 0.074\n",
            "[128,   100] loss: 0.105\n",
            "[128,   120] loss: 0.042\n",
            "0.908908704010298\n",
            "SpearmanrResult(correlation=0.6030085362549102, pvalue=1.2452819145063045e-43)\n",
            "[129,    20] loss: 0.069\n",
            "[129,    40] loss: 0.091\n",
            "[129,    60] loss: 0.028\n",
            "[129,    80] loss: 0.055\n",
            "[129,   100] loss: 0.018\n",
            "[129,   120] loss: 0.209\n",
            "[130,    20] loss: 0.152\n",
            "[130,    40] loss: 0.072\n",
            "[130,    60] loss: 0.165\n",
            "[130,    80] loss: 0.070\n",
            "[130,   100] loss: 0.237\n",
            "[130,   120] loss: 0.478\n",
            "[131,    20] loss: 0.084\n",
            "[131,    40] loss: 0.082\n",
            "[131,    60] loss: 0.039\n",
            "[131,    80] loss: 0.093\n",
            "[131,   100] loss: 0.094\n",
            "[131,   120] loss: 0.193\n",
            "[132,    20] loss: 0.090\n",
            "[132,    40] loss: 0.095\n",
            "[132,    60] loss: 0.065\n",
            "[132,    80] loss: 0.093\n",
            "[132,   100] loss: 0.124\n",
            "[132,   120] loss: 0.072\n",
            "0.9042653088568476\n",
            "SpearmanrResult(correlation=0.658624250531245, pvalue=1.887681558407651e-54)\n",
            "[133,    20] loss: 0.078\n",
            "[133,    40] loss: 0.075\n",
            "[133,    60] loss: 0.070\n",
            "[133,    80] loss: 0.052\n",
            "[133,   100] loss: 0.057\n",
            "[133,   120] loss: 0.067\n",
            "[134,    20] loss: 0.045\n",
            "[134,    40] loss: 0.046\n",
            "[134,    60] loss: 0.035\n",
            "[134,    80] loss: 0.034\n",
            "[134,   100] loss: 0.064\n",
            "[134,   120] loss: 0.043\n",
            "[135,    20] loss: 0.042\n",
            "[135,    40] loss: 0.037\n",
            "[135,    60] loss: 0.024\n",
            "[135,    80] loss: 0.042\n",
            "[135,   100] loss: 0.036\n",
            "[135,   120] loss: 0.053\n",
            "[136,    20] loss: 0.030\n",
            "[136,    40] loss: 0.029\n",
            "[136,    60] loss: 0.018\n",
            "[136,    80] loss: 0.022\n",
            "[136,   100] loss: 0.029\n",
            "[136,   120] loss: 0.039\n",
            "0.9235664912483246\n",
            "SpearmanrResult(correlation=0.677901492321172, pvalue=9.238676332765821e-59)\n",
            "[137,    20] loss: 0.048\n",
            "[137,    40] loss: 0.051\n",
            "[137,    60] loss: 0.042\n",
            "[137,    80] loss: 0.033\n",
            "[137,   100] loss: 0.032\n",
            "[137,   120] loss: 0.025\n",
            "[138,    20] loss: 0.039\n",
            "[138,    40] loss: 0.072\n",
            "[138,    60] loss: 0.059\n",
            "[138,    80] loss: 0.068\n",
            "[138,   100] loss: 0.035\n",
            "[138,   120] loss: 0.039\n",
            "[139,    20] loss: 0.064\n",
            "[139,    40] loss: 0.045\n",
            "[139,    60] loss: 0.041\n",
            "[139,    80] loss: 0.041\n",
            "[139,   100] loss: 0.051\n",
            "[139,   120] loss: 0.060\n",
            "[140,    20] loss: 0.038\n",
            "[140,    40] loss: 0.053\n",
            "[140,    60] loss: 0.050\n",
            "[140,    80] loss: 0.057\n",
            "[140,   100] loss: 0.028\n",
            "[140,   120] loss: 0.020\n",
            "0.9201440311507895\n",
            "SpearmanrResult(correlation=0.6762499893520599, pvalue=2.2271900140293376e-58)\n",
            "[141,    20] loss: 0.089\n",
            "[141,    40] loss: 0.096\n",
            "[141,    60] loss: 0.032\n",
            "[141,    80] loss: 0.021\n",
            "[141,   100] loss: 0.030\n",
            "[141,   120] loss: 0.064\n",
            "[142,    20] loss: 0.029\n",
            "[142,    40] loss: 0.038\n",
            "[142,    60] loss: 0.037\n",
            "[142,    80] loss: 0.038\n",
            "[142,   100] loss: 0.043\n",
            "[142,   120] loss: 0.033\n",
            "[143,    20] loss: 0.069\n",
            "[143,    40] loss: 0.042\n",
            "[143,    60] loss: 0.049\n",
            "[143,    80] loss: 0.056\n",
            "[143,   100] loss: 0.073\n",
            "[143,   120] loss: 0.109\n",
            "[144,    20] loss: 0.037\n",
            "[144,    40] loss: 0.075\n",
            "[144,    60] loss: 0.071\n",
            "[144,    80] loss: 0.107\n",
            "[144,   100] loss: 0.066\n",
            "[144,   120] loss: 0.064\n",
            "0.8861325367766012\n",
            "SpearmanrResult(correlation=0.6511630567384711, pvalue=7.245561247852223e-53)\n",
            "[145,    20] loss: 0.107\n",
            "[145,    40] loss: 0.110\n",
            "[145,    60] loss: 0.052\n",
            "[145,    80] loss: 0.057\n",
            "[145,   100] loss: 0.030\n",
            "[145,   120] loss: 0.044\n",
            "[146,    20] loss: 0.049\n",
            "[146,    40] loss: 0.028\n",
            "[146,    60] loss: 0.065\n",
            "[146,    80] loss: 0.036\n",
            "[146,   100] loss: 0.032\n",
            "[146,   120] loss: 0.060\n",
            "[147,    20] loss: 0.064\n",
            "[147,    40] loss: 0.021\n",
            "[147,    60] loss: 0.050\n",
            "[147,    80] loss: 0.059\n",
            "[147,   100] loss: 0.041\n",
            "[147,   120] loss: 0.045\n",
            "[148,    20] loss: 0.025\n",
            "[148,    40] loss: 0.038\n",
            "[148,    60] loss: 0.036\n",
            "[148,    80] loss: 0.099\n",
            "[148,   100] loss: 0.081\n",
            "[148,   120] loss: 0.082\n",
            "0.8970013313134682\n",
            "SpearmanrResult(correlation=0.6180102546893483, pvalue=2.451154983949853e-46)\n",
            "[149,    20] loss: 0.056\n",
            "[149,    40] loss: 0.061\n",
            "[149,    60] loss: 0.030\n",
            "[149,    80] loss: 0.090\n",
            "[149,   100] loss: 0.073\n",
            "[149,   120] loss: 0.174\n",
            "[150,    20] loss: 0.030\n",
            "[150,    40] loss: 0.053\n",
            "[150,    60] loss: 0.063\n",
            "[150,    80] loss: 0.030\n",
            "[150,   100] loss: 0.155\n",
            "[150,   120] loss: 0.060\n",
            "[151,    20] loss: 0.036\n",
            "[151,    40] loss: 0.049\n",
            "[151,    60] loss: 0.046\n",
            "[151,    80] loss: 0.068\n",
            "[151,   100] loss: 0.028\n",
            "[151,   120] loss: 0.047\n",
            "[152,    20] loss: 0.065\n",
            "[152,    40] loss: 0.022\n",
            "[152,    60] loss: 0.038\n",
            "[152,    80] loss: 0.027\n",
            "[152,   100] loss: 0.034\n",
            "[152,   120] loss: 0.033\n",
            "0.8956587653977975\n",
            "SpearmanrResult(correlation=0.6704628541348987, pvalue=4.649255045661117e-57)\n",
            "[153,    20] loss: 0.027\n",
            "[153,    40] loss: 0.034\n",
            "[153,    60] loss: 0.017\n",
            "[153,    80] loss: 0.063\n",
            "[153,   100] loss: 0.059\n",
            "[153,   120] loss: 0.061\n",
            "[154,    20] loss: 0.028\n",
            "[154,    40] loss: 0.022\n",
            "[154,    60] loss: 0.024\n",
            "[154,    80] loss: 0.026\n",
            "[154,   100] loss: 0.119\n",
            "[154,   120] loss: 0.067\n",
            "[155,    20] loss: 0.034\n",
            "[155,    40] loss: 0.025\n",
            "[155,    60] loss: 0.046\n",
            "[155,    80] loss: 0.065\n",
            "[155,   100] loss: 0.038\n",
            "[155,   120] loss: 0.036\n",
            "[156,    20] loss: 0.053\n",
            "[156,    40] loss: 0.068\n",
            "[156,    60] loss: 0.028\n",
            "[156,    80] loss: 0.042\n",
            "[156,   100] loss: 0.139\n",
            "[156,   120] loss: 0.147\n",
            "0.827192635635194\n",
            "SpearmanrResult(correlation=0.6443012086677431, pvalue=1.896836638090426e-51)\n",
            "[157,    20] loss: 0.078\n",
            "[157,    40] loss: 0.064\n",
            "[157,    60] loss: 0.115\n",
            "[157,    80] loss: 0.222\n",
            "[157,   100] loss: 0.184\n",
            "[157,   120] loss: 0.130\n",
            "[158,    20] loss: 0.105\n",
            "[158,    40] loss: 0.094\n",
            "[158,    60] loss: 0.117\n",
            "[158,    80] loss: 0.048\n",
            "[158,   100] loss: 0.061\n",
            "[158,   120] loss: 0.042\n",
            "[159,    20] loss: 0.032\n",
            "[159,    40] loss: 0.047\n",
            "[159,    60] loss: 0.050\n",
            "[159,    80] loss: 0.037\n",
            "[159,   100] loss: 0.046\n",
            "[159,   120] loss: 0.494\n",
            "[160,    20] loss: 0.056\n",
            "[160,    40] loss: 0.049\n",
            "[160,    60] loss: 0.089\n",
            "[160,    80] loss: 0.058\n",
            "[160,   100] loss: 0.079\n",
            "[160,   120] loss: 0.085\n",
            "0.9086286791033235\n",
            "SpearmanrResult(correlation=0.6394665071086338, pvalue=1.800733186711385e-50)\n",
            "[161,    20] loss: 0.086\n",
            "[161,    40] loss: 0.065\n",
            "[161,    60] loss: 0.048\n",
            "[161,    80] loss: 0.107\n",
            "[161,   100] loss: 0.043\n",
            "[161,   120] loss: 0.024\n",
            "[162,    20] loss: 0.030\n",
            "[162,    40] loss: 0.032\n",
            "[162,    60] loss: 0.048\n",
            "[162,    80] loss: 0.032\n",
            "[162,   100] loss: 0.027\n",
            "[162,   120] loss: 0.021\n",
            "[163,    20] loss: 0.047\n",
            "[163,    40] loss: 0.025\n",
            "[163,    60] loss: 0.042\n",
            "[163,    80] loss: 0.041\n",
            "[163,   100] loss: 0.021\n",
            "[163,   120] loss: 0.041\n",
            "[164,    20] loss: 0.034\n",
            "[164,    40] loss: 0.050\n",
            "[164,    60] loss: 0.018\n",
            "[164,    80] loss: 0.020\n",
            "[164,   100] loss: 0.038\n",
            "[164,   120] loss: 0.027\n",
            "0.902396357132187\n",
            "SpearmanrResult(correlation=0.6996878908438245, pvalue=4.77762313831798e-64)\n",
            "[165,    20] loss: 0.024\n",
            "[165,    40] loss: 0.023\n",
            "[165,    60] loss: 0.037\n",
            "[165,    80] loss: 0.032\n",
            "[165,   100] loss: 0.068\n",
            "[165,   120] loss: 0.023\n",
            "[166,    20] loss: 0.131\n",
            "[166,    40] loss: 0.053\n",
            "[166,    60] loss: 0.044\n",
            "[166,    80] loss: 0.023\n",
            "[166,   100] loss: 0.035\n",
            "[166,   120] loss: 0.033\n",
            "[167,    20] loss: 0.037\n",
            "[167,    40] loss: 0.042\n",
            "[167,    60] loss: 0.026\n",
            "[167,    80] loss: 0.031\n",
            "[167,   100] loss: 0.027\n",
            "[167,   120] loss: 0.027\n",
            "[168,    20] loss: 0.032\n",
            "[168,    40] loss: 0.054\n",
            "[168,    60] loss: 0.037\n",
            "[168,    80] loss: 0.020\n",
            "[168,   100] loss: 0.032\n",
            "[168,   120] loss: 0.038\n",
            "0.9146916957186223\n",
            "SpearmanrResult(correlation=0.7074013675504018, pvalue=4.909045145316995e-66)\n",
            "[169,    20] loss: 0.019\n",
            "[169,    40] loss: 0.015\n",
            "[169,    60] loss: 0.040\n",
            "[169,    80] loss: 0.024\n",
            "[169,   100] loss: 0.027\n",
            "[169,   120] loss: 0.047\n",
            "[170,    20] loss: 0.021\n",
            "[170,    40] loss: 0.019\n",
            "[170,    60] loss: 0.023\n",
            "[170,    80] loss: 0.013\n",
            "[170,   100] loss: 0.015\n",
            "[170,   120] loss: 0.040\n",
            "[171,    20] loss: 0.028\n",
            "[171,    40] loss: 0.019\n",
            "[171,    60] loss: 0.025\n",
            "[171,    80] loss: 0.034\n",
            "[171,   100] loss: 0.010\n",
            "[171,   120] loss: 0.035\n",
            "[172,    20] loss: 0.022\n",
            "[172,    40] loss: 0.021\n",
            "[172,    60] loss: 0.039\n",
            "[172,    80] loss: 0.023\n",
            "[172,   100] loss: 0.057\n",
            "[172,   120] loss: 0.051\n",
            "0.8958099498429359\n",
            "SpearmanrResult(correlation=0.667921254406522, pvalue=1.7279988457328981e-56)\n",
            "[173,    20] loss: 0.020\n",
            "[173,    40] loss: 0.027\n",
            "[173,    60] loss: 0.076\n",
            "[173,    80] loss: 0.027\n",
            "[173,   100] loss: 0.179\n",
            "[173,   120] loss: 0.100\n",
            "[174,    20] loss: 0.028\n",
            "[174,    40] loss: 0.075\n",
            "[174,    60] loss: 0.066\n",
            "[174,    80] loss: 0.034\n",
            "[174,   100] loss: 0.044\n",
            "[174,   120] loss: 0.040\n",
            "[175,    20] loss: 0.064\n",
            "[175,    40] loss: 0.062\n",
            "[175,    60] loss: 0.024\n",
            "[175,    80] loss: 0.026\n",
            "[175,   100] loss: 0.028\n",
            "[175,   120] loss: 0.047\n",
            "[176,    20] loss: 0.071\n",
            "[176,    40] loss: 0.046\n",
            "[176,    60] loss: 0.039\n",
            "[176,    80] loss: 0.090\n",
            "[176,   100] loss: 0.025\n",
            "[176,   120] loss: 0.034\n",
            "0.8859438844405697\n",
            "SpearmanrResult(correlation=0.7020576199404766, pvalue=1.1890964176091297e-64)\n",
            "[177,    20] loss: 0.034\n",
            "[177,    40] loss: 0.064\n",
            "[177,    60] loss: 0.089\n",
            "[177,    80] loss: 0.102\n",
            "[177,   100] loss: 0.051\n",
            "[177,   120] loss: 0.147\n",
            "[178,    20] loss: 0.019\n",
            "[178,    40] loss: 0.066\n",
            "[178,    60] loss: 0.032\n",
            "[178,    80] loss: 0.063\n",
            "[178,   100] loss: 0.030\n",
            "[178,   120] loss: 0.103\n",
            "[179,    20] loss: 0.053\n",
            "[179,    40] loss: 0.143\n",
            "[179,    60] loss: 0.041\n",
            "[179,    80] loss: 0.018\n",
            "[179,   100] loss: 0.030\n",
            "[179,   120] loss: 0.027\n",
            "[180,    20] loss: 0.046\n",
            "[180,    40] loss: 0.055\n",
            "[180,    60] loss: 0.044\n",
            "[180,    80] loss: 0.034\n",
            "[180,   100] loss: 0.061\n",
            "[180,   120] loss: 0.013\n",
            "0.9154061582481834\n",
            "SpearmanrResult(correlation=0.7106222618115369, pvalue=6.941413068700456e-67)\n",
            "[181,    20] loss: 0.051\n",
            "[181,    40] loss: 0.039\n",
            "[181,    60] loss: 0.050\n",
            "[181,    80] loss: 0.017\n",
            "[181,   100] loss: 0.045\n",
            "[181,   120] loss: 0.015\n",
            "[182,    20] loss: 0.027\n",
            "[182,    40] loss: 0.041\n",
            "[182,    60] loss: 0.032\n",
            "[182,    80] loss: 0.014\n",
            "[182,   100] loss: 0.010\n",
            "[182,   120] loss: 0.029\n",
            "[183,    20] loss: 0.027\n",
            "[183,    40] loss: 0.033\n",
            "[183,    60] loss: 0.018\n",
            "[183,    80] loss: 0.029\n",
            "[183,   100] loss: 0.052\n",
            "[183,   120] loss: 0.030\n",
            "[184,    20] loss: 0.016\n",
            "[184,    40] loss: 0.025\n",
            "[184,    60] loss: 0.033\n",
            "[184,    80] loss: 0.025\n",
            "[184,   100] loss: 0.025\n",
            "[184,   120] loss: 0.023\n",
            "0.9160703004733732\n",
            "SpearmanrResult(correlation=0.7159382783847031, pvalue=2.5909426573186287e-68)\n",
            "[185,    20] loss: 0.022\n",
            "[185,    40] loss: 0.013\n",
            "[185,    60] loss: 0.008\n",
            "[185,    80] loss: 0.107\n",
            "[185,   100] loss: 0.017\n",
            "[185,   120] loss: 0.015\n",
            "[186,    20] loss: 0.032\n",
            "[186,    40] loss: 0.038\n",
            "[186,    60] loss: 0.018\n",
            "[186,    80] loss: 0.042\n",
            "[186,   100] loss: 0.032\n",
            "[186,   120] loss: 0.024\n",
            "[187,    20] loss: 0.014\n",
            "[187,    40] loss: 0.073\n",
            "[187,    60] loss: 0.078\n",
            "[187,    80] loss: 0.062\n",
            "[187,   100] loss: 0.021\n",
            "[187,   120] loss: 0.045\n",
            "[188,    20] loss: 0.020\n",
            "[188,    40] loss: 0.019\n",
            "[188,    60] loss: 0.052\n",
            "[188,    80] loss: 0.077\n",
            "[188,   100] loss: 0.066\n",
            "[188,   120] loss: 0.045\n",
            "0.8995379612743566\n",
            "SpearmanrResult(correlation=0.6684450542958367, pvalue=1.3197777596922218e-56)\n",
            "[189,    20] loss: 0.053\n",
            "[189,    40] loss: 0.018\n",
            "[189,    60] loss: 0.034\n",
            "[189,    80] loss: 0.015\n",
            "[189,   100] loss: 0.022\n",
            "[189,   120] loss: 0.070\n",
            "[190,    20] loss: 0.053\n",
            "[190,    40] loss: 0.059\n",
            "[190,    60] loss: 0.034\n",
            "[190,    80] loss: 0.034\n",
            "[190,   100] loss: 0.045\n",
            "[190,   120] loss: 0.024\n",
            "[191,    20] loss: 0.024\n",
            "[191,    40] loss: 0.042\n",
            "[191,    60] loss: 0.048\n",
            "[191,    80] loss: 0.052\n",
            "[191,   100] loss: 0.047\n",
            "[191,   120] loss: 0.051\n",
            "[192,    20] loss: 0.024\n",
            "[192,    40] loss: 0.050\n",
            "[192,    60] loss: 0.046\n",
            "[192,    80] loss: 0.021\n",
            "[192,   100] loss: 0.038\n",
            "[192,   120] loss: 0.027\n",
            "0.9148182784392294\n",
            "SpearmanrResult(correlation=0.719790497892169, pvalue=2.280362086543444e-69)\n",
            "[193,    20] loss: 0.013\n",
            "[193,    40] loss: 0.060\n",
            "[193,    60] loss: 0.027\n",
            "[193,    80] loss: 0.020\n",
            "[193,   100] loss: 0.020\n",
            "[193,   120] loss: 0.018\n",
            "[194,    20] loss: 0.013\n",
            "[194,    40] loss: 0.016\n",
            "[194,    60] loss: 0.023\n",
            "[194,    80] loss: 0.015\n",
            "[194,   100] loss: 0.051\n",
            "[194,   120] loss: 0.043\n",
            "[195,    20] loss: 0.029\n",
            "[195,    40] loss: 0.059\n",
            "[195,    60] loss: 0.078\n",
            "[195,    80] loss: 0.052\n",
            "[195,   100] loss: 0.027\n",
            "[195,   120] loss: 0.036\n",
            "[196,    20] loss: 0.009\n",
            "[196,    40] loss: 0.035\n",
            "[196,    60] loss: 0.036\n",
            "[196,    80] loss: 0.056\n",
            "[196,   100] loss: 0.035\n",
            "[196,   120] loss: 0.043\n",
            "0.8953669358335785\n",
            "SpearmanrResult(correlation=0.6967355782395465, pvalue=2.651074166478819e-63)\n",
            "[197,    20] loss: 0.039\n",
            "[197,    40] loss: 0.020\n",
            "[197,    60] loss: 0.021\n",
            "[197,    80] loss: 0.038\n",
            "[197,   100] loss: 0.035\n",
            "[197,   120] loss: 0.024\n",
            "[198,    20] loss: 0.055\n",
            "[198,    40] loss: 0.042\n",
            "[198,    60] loss: 0.053\n",
            "[198,    80] loss: 0.038\n",
            "[198,   100] loss: 0.058\n",
            "[198,   120] loss: 0.037\n",
            "[199,    20] loss: 0.020\n",
            "[199,    40] loss: 0.018\n",
            "[199,    60] loss: 0.044\n",
            "[199,    80] loss: 0.095\n",
            "[199,   100] loss: 0.046\n",
            "[199,   120] loss: 0.030\n",
            "[200,    20] loss: 0.058\n",
            "[200,    40] loss: 0.028\n",
            "[200,    60] loss: 0.028\n",
            "[200,    80] loss: 0.028\n",
            "[200,   100] loss: 0.045\n",
            "[200,   120] loss: 0.022\n",
            "0.9115767417209506\n",
            "SpearmanrResult(correlation=0.7201681498105968, pvalue=1.7929867849082232e-69)\n",
            "[201,    20] loss: 0.041\n",
            "[201,    40] loss: 0.026\n",
            "[201,    60] loss: 0.010\n",
            "[201,    80] loss: 0.035\n",
            "[201,   100] loss: 0.073\n",
            "[201,   120] loss: 0.054\n",
            "[202,    20] loss: 0.039\n",
            "[202,    40] loss: 0.080\n",
            "[202,    60] loss: 0.031\n",
            "[202,    80] loss: 0.037\n",
            "[202,   100] loss: 0.054\n",
            "[202,   120] loss: 0.130\n",
            "[203,    20] loss: 0.052\n",
            "[203,    40] loss: 0.025\n",
            "[203,    60] loss: 0.030\n",
            "[203,    80] loss: 0.048\n",
            "[203,   100] loss: 0.030\n",
            "[203,   120] loss: 0.015\n",
            "[204,    20] loss: 0.043\n",
            "[204,    40] loss: 0.034\n",
            "[204,    60] loss: 0.087\n",
            "[204,    80] loss: 0.050\n",
            "[204,   100] loss: 0.039\n",
            "[204,   120] loss: 0.027\n",
            "0.9122279098468025\n",
            "SpearmanrResult(correlation=0.7180551066057297, pvalue=6.849566415778992e-69)\n",
            "[205,    20] loss: 0.009\n",
            "[205,    40] loss: 0.023\n",
            "[205,    60] loss: 0.017\n",
            "[205,    80] loss: 0.017\n",
            "[205,   100] loss: 0.010\n",
            "[205,   120] loss: 0.033\n",
            "[206,    20] loss: 0.025\n",
            "[206,    40] loss: 0.022\n",
            "[206,    60] loss: 0.043\n",
            "[206,    80] loss: 0.041\n",
            "[206,   100] loss: 0.014\n",
            "[206,   120] loss: 0.028\n",
            "[207,    20] loss: 0.026\n",
            "[207,    40] loss: 0.017\n",
            "[207,    60] loss: 0.025\n",
            "[207,    80] loss: 0.009\n",
            "[207,   100] loss: 0.034\n",
            "[207,   120] loss: 0.023\n",
            "[208,    20] loss: 0.052\n",
            "[208,    40] loss: 0.021\n",
            "[208,    60] loss: 0.012\n",
            "[208,    80] loss: 0.022\n",
            "[208,   100] loss: 0.026\n",
            "[208,   120] loss: 0.017\n",
            "0.9077898048261644\n",
            "SpearmanrResult(correlation=0.7040759604961327, pvalue=3.5978769250832005e-65)\n",
            "[209,    20] loss: 0.027\n",
            "[209,    40] loss: 0.022\n",
            "[209,    60] loss: 0.037\n",
            "[209,    80] loss: 0.027\n",
            "[209,   100] loss: 0.022\n",
            "[209,   120] loss: 0.026\n",
            "[210,    20] loss: 0.030\n",
            "[210,    40] loss: 0.022\n",
            "[210,    60] loss: 0.042\n",
            "[210,    80] loss: 0.038\n",
            "[210,   100] loss: 0.023\n",
            "[210,   120] loss: 0.043\n",
            "[211,    20] loss: 0.058\n",
            "[211,    40] loss: 0.024\n",
            "[211,    60] loss: 0.015\n",
            "[211,    80] loss: 0.022\n",
            "[211,   100] loss: 0.013\n",
            "[211,   120] loss: 0.023\n",
            "[212,    20] loss: 0.022\n",
            "[212,    40] loss: 0.042\n",
            "[212,    60] loss: 0.020\n",
            "[212,    80] loss: 0.028\n",
            "[212,   100] loss: 0.040\n",
            "[212,   120] loss: 0.015\n",
            "0.922161320044113\n",
            "SpearmanrResult(correlation=0.700554427808628, pvalue=2.8776705511719137e-64)\n",
            "[213,    20] loss: 0.025\n",
            "[213,    40] loss: 0.050\n",
            "[213,    60] loss: 0.015\n",
            "[213,    80] loss: 0.024\n",
            "[213,   100] loss: 0.010\n",
            "[213,   120] loss: 0.020\n",
            "[214,    20] loss: 0.012\n",
            "[214,    40] loss: 0.028\n",
            "[214,    60] loss: 0.017\n",
            "[214,    80] loss: 0.018\n",
            "[214,   100] loss: 0.026\n",
            "[214,   120] loss: 0.036\n",
            "[215,    20] loss: 0.021\n",
            "[215,    40] loss: 0.025\n",
            "[215,    60] loss: 0.026\n",
            "[215,    80] loss: 0.024\n",
            "[215,   100] loss: 0.020\n",
            "[215,   120] loss: 0.024\n",
            "[216,    20] loss: 0.023\n",
            "[216,    40] loss: 0.046\n",
            "[216,    60] loss: 0.023\n",
            "[216,    80] loss: 0.020\n",
            "[216,   100] loss: 0.040\n",
            "[216,   120] loss: 0.015\n",
            "0.895753008447946\n",
            "SpearmanrResult(correlation=0.6562576112437025, pvalue=6.071405150141441e-54)\n",
            "[217,    20] loss: 0.024\n",
            "[217,    40] loss: 0.021\n",
            "[217,    60] loss: 0.021\n",
            "[217,    80] loss: 0.022\n",
            "[217,   100] loss: 0.056\n",
            "[217,   120] loss: 0.023\n",
            "[218,    20] loss: 0.045\n",
            "[218,    40] loss: 0.058\n",
            "[218,    60] loss: 0.018\n",
            "[218,    80] loss: 0.022\n",
            "[218,   100] loss: 0.043\n",
            "[218,   120] loss: 0.029\n",
            "[219,    20] loss: 0.023\n",
            "[219,    40] loss: 0.041\n",
            "[219,    60] loss: 0.088\n",
            "[219,    80] loss: 0.034\n",
            "[219,   100] loss: 0.016\n",
            "[219,   120] loss: 0.051\n",
            "[220,    20] loss: 0.034\n",
            "[220,    40] loss: 0.031\n",
            "[220,    60] loss: 0.020\n",
            "[220,    80] loss: 0.024\n",
            "[220,   100] loss: 0.022\n",
            "[220,   120] loss: 0.025\n",
            "0.8971162667078242\n",
            "SpearmanrResult(correlation=0.7008694338473576, pvalue=2.392251618560466e-64)\n",
            "[221,    20] loss: 0.037\n",
            "[221,    40] loss: 0.038\n",
            "[221,    60] loss: 0.097\n",
            "[221,    80] loss: 0.023\n",
            "[221,   100] loss: 0.015\n",
            "[221,   120] loss: 0.029\n",
            "[222,    20] loss: 0.087\n",
            "[222,    40] loss: 0.064\n",
            "[222,    60] loss: 0.086\n",
            "[222,    80] loss: 0.038\n",
            "[222,   100] loss: 0.025\n",
            "[222,   120] loss: 0.035\n",
            "[223,    20] loss: 0.022\n",
            "[223,    40] loss: 0.018\n",
            "[223,    60] loss: 0.033\n",
            "[223,    80] loss: 0.026\n",
            "[223,   100] loss: 0.023\n",
            "[223,   120] loss: 0.031\n",
            "[224,    20] loss: 0.078\n",
            "[224,    40] loss: 0.031\n",
            "[224,    60] loss: 0.016\n",
            "[224,    80] loss: 0.035\n",
            "[224,   100] loss: 0.015\n",
            "[224,   120] loss: 0.021\n",
            "0.9141366644157769\n",
            "SpearmanrResult(correlation=0.7447128981706684, pvalue=1.1875932049331127e-76)\n",
            "[225,    20] loss: 0.016\n",
            "[225,    40] loss: 0.028\n",
            "[225,    60] loss: 0.014\n",
            "[225,    80] loss: 0.019\n",
            "[225,   100] loss: 0.019\n",
            "[225,   120] loss: 0.053\n",
            "[226,    20] loss: 0.039\n",
            "[226,    40] loss: 0.011\n",
            "[226,    60] loss: 0.046\n",
            "[226,    80] loss: 0.051\n",
            "[226,   100] loss: 0.062\n",
            "[226,   120] loss: 0.033\n",
            "[227,    20] loss: 0.026\n",
            "[227,    40] loss: 0.038\n",
            "[227,    60] loss: 0.026\n",
            "[227,    80] loss: 0.040\n",
            "[227,   100] loss: 0.046\n",
            "[227,   120] loss: 0.025\n",
            "[228,    20] loss: 0.027\n",
            "[228,    40] loss: 0.014\n",
            "[228,    60] loss: 0.021\n",
            "[228,    80] loss: 0.028\n",
            "[228,   100] loss: 0.012\n",
            "[228,   120] loss: 0.044\n",
            "0.9086238935836743\n",
            "SpearmanrResult(correlation=0.6845015563150844, pvalue=2.5885412707313653e-60)\n",
            "[229,    20] loss: 0.013\n",
            "[229,    40] loss: 0.014\n",
            "[229,    60] loss: 0.010\n",
            "[229,    80] loss: 0.026\n",
            "[229,   100] loss: 0.025\n",
            "[229,   120] loss: 0.020\n",
            "[230,    20] loss: 0.029\n",
            "[230,    40] loss: 0.053\n",
            "[230,    60] loss: 0.012\n",
            "[230,    80] loss: 0.015\n",
            "[230,   100] loss: 0.016\n",
            "[230,   120] loss: 0.022\n",
            "[231,    20] loss: 0.015\n",
            "[231,    40] loss: 0.014\n",
            "[231,    60] loss: 0.044\n",
            "[231,    80] loss: 0.020\n",
            "[231,   100] loss: 0.016\n",
            "[231,   120] loss: 0.041\n",
            "[232,    20] loss: 0.017\n",
            "[232,    40] loss: 0.023\n",
            "[232,    60] loss: 0.012\n",
            "[232,    80] loss: 0.031\n",
            "[232,   100] loss: 0.031\n",
            "[232,   120] loss: 0.031\n",
            "0.9103120480821492\n",
            "SpearmanrResult(correlation=0.7255422547950247, pvalue=5.6059435295274666e-71)\n",
            "[233,    20] loss: 0.032\n",
            "[233,    40] loss: 0.015\n",
            "[233,    60] loss: 0.034\n",
            "[233,    80] loss: 0.016\n",
            "[233,   100] loss: 0.034\n",
            "[233,   120] loss: 0.036\n",
            "[234,    20] loss: 0.032\n",
            "[234,    40] loss: 0.050\n",
            "[234,    60] loss: 0.017\n",
            "[234,    80] loss: 0.020\n",
            "[234,   100] loss: 0.016\n",
            "[234,   120] loss: 0.016\n",
            "[235,    20] loss: 0.049\n",
            "[235,    40] loss: 0.028\n",
            "[235,    60] loss: 0.016\n",
            "[235,    80] loss: 0.010\n",
            "[235,   100] loss: 0.076\n",
            "[235,   120] loss: 0.039\n",
            "[236,    20] loss: 0.024\n",
            "[236,    40] loss: 0.046\n",
            "[236,    60] loss: 0.013\n",
            "[236,    80] loss: 0.059\n",
            "[236,   100] loss: 0.032\n",
            "[236,   120] loss: 0.029\n",
            "0.9055227139719111\n",
            "SpearmanrResult(correlation=0.7103197694997013, pvalue=8.350835707189678e-67)\n",
            "[237,    20] loss: 0.048\n",
            "[237,    40] loss: 0.097\n",
            "[237,    60] loss: 0.029\n",
            "[237,    80] loss: 0.022\n",
            "[237,   100] loss: 0.018\n",
            "[237,   120] loss: 0.013\n",
            "[238,    20] loss: 0.031\n",
            "[238,    40] loss: 0.029\n",
            "[238,    60] loss: 0.013\n",
            "[238,    80] loss: 0.014\n",
            "[238,   100] loss: 0.018\n",
            "[238,   120] loss: 0.024\n",
            "[239,    20] loss: 0.026\n",
            "[239,    40] loss: 0.020\n",
            "[239,    60] loss: 0.065\n",
            "[239,    80] loss: 0.036\n",
            "[239,   100] loss: 0.016\n",
            "[239,   120] loss: 0.011\n",
            "[240,    20] loss: 0.016\n",
            "[240,    40] loss: 0.021\n",
            "[240,    60] loss: 0.031\n",
            "[240,    80] loss: 0.012\n",
            "[240,   100] loss: 0.017\n",
            "[240,   120] loss: 0.055\n",
            "0.9049340919328258\n",
            "SpearmanrResult(correlation=0.7335970781629914, pvalue=2.6587862435898774e-73)\n",
            "[241,    20] loss: 0.050\n",
            "[241,    40] loss: 0.035\n",
            "[241,    60] loss: 0.038\n",
            "[241,    80] loss: 0.048\n",
            "[241,   100] loss: 0.017\n",
            "[241,   120] loss: 0.015\n",
            "[242,    20] loss: 0.047\n",
            "[242,    40] loss: 0.027\n",
            "[242,    60] loss: 0.173\n",
            "[242,    80] loss: 0.065\n",
            "[242,   100] loss: 0.106\n",
            "[242,   120] loss: 0.102\n",
            "[243,    20] loss: 0.054\n",
            "[243,    40] loss: 0.067\n",
            "[243,    60] loss: 0.030\n",
            "[243,    80] loss: 0.051\n",
            "[243,   100] loss: 0.056\n",
            "[243,   120] loss: 0.106\n",
            "[244,    20] loss: 0.017\n",
            "[244,    40] loss: 0.045\n",
            "[244,    60] loss: 0.015\n",
            "[244,    80] loss: 0.019\n",
            "[244,   100] loss: 0.034\n",
            "[244,   120] loss: 0.050\n",
            "0.9165335078264581\n",
            "SpearmanrResult(correlation=0.7009498461294366, pvalue=2.281962014181962e-64)\n",
            "[245,    20] loss: 0.030\n",
            "[245,    40] loss: 0.022\n",
            "[245,    60] loss: 0.029\n",
            "[245,    80] loss: 0.037\n",
            "[245,   100] loss: 0.029\n",
            "[245,   120] loss: 0.029\n",
            "[246,    20] loss: 0.027\n",
            "[246,    40] loss: 0.029\n",
            "[246,    60] loss: 0.037\n",
            "[246,    80] loss: 0.019\n",
            "[246,   100] loss: 0.053\n",
            "[246,   120] loss: 0.016\n",
            "[247,    20] loss: 0.019\n",
            "[247,    40] loss: 0.080\n",
            "[247,    60] loss: 0.020\n",
            "[247,    80] loss: 0.034\n",
            "[247,   100] loss: 0.028\n",
            "[247,   120] loss: 0.008\n",
            "[248,    20] loss: 0.020\n",
            "[248,    40] loss: 0.012\n",
            "[248,    60] loss: 0.047\n",
            "[248,    80] loss: 0.048\n",
            "[248,   100] loss: 0.050\n",
            "[248,   120] loss: 0.026\n",
            "0.9132056897859517\n",
            "SpearmanrResult(correlation=0.7197892619685251, pvalue=2.2821557568498472e-69)\n",
            "[249,    20] loss: 0.027\n",
            "[249,    40] loss: 0.012\n",
            "[249,    60] loss: 0.037\n",
            "[249,    80] loss: 0.015\n",
            "[249,   100] loss: 0.013\n",
            "[249,   120] loss: 0.015\n",
            "[250,    20] loss: 0.019\n",
            "[250,    40] loss: 0.031\n",
            "[250,    60] loss: 0.016\n",
            "[250,    80] loss: 0.009\n",
            "[250,   100] loss: 0.009\n",
            "[250,   120] loss: 0.020\n",
            "[251,    20] loss: 0.017\n",
            "[251,    40] loss: 0.022\n",
            "[251,    60] loss: 0.030\n",
            "[251,    80] loss: 0.012\n",
            "[251,   100] loss: 0.012\n",
            "[251,   120] loss: 0.022\n",
            "[252,    20] loss: 0.024\n",
            "[252,    40] loss: 0.018\n",
            "[252,    60] loss: 0.016\n",
            "[252,    80] loss: 0.018\n",
            "[252,   100] loss: 0.020\n",
            "[252,   120] loss: 0.066\n",
            "0.9214751233745161\n",
            "SpearmanrResult(correlation=0.7372016494703182, pvalue=2.2752967388061695e-74)\n",
            "[253,    20] loss: 0.011\n",
            "[253,    40] loss: 0.013\n",
            "[253,    60] loss: 0.014\n",
            "[253,    80] loss: 0.044\n",
            "[253,   100] loss: 0.012\n",
            "[253,   120] loss: 0.013\n",
            "[254,    20] loss: 0.011\n",
            "[254,    40] loss: 0.011\n",
            "[254,    60] loss: 0.008\n",
            "[254,    80] loss: 0.021\n",
            "[254,   100] loss: 0.025\n",
            "[254,   120] loss: 0.023\n",
            "[255,    20] loss: 0.041\n",
            "[255,    40] loss: 0.039\n",
            "[255,    60] loss: 0.019\n",
            "[255,    80] loss: 0.013\n",
            "[255,   100] loss: 0.013\n",
            "[255,   120] loss: 0.022\n",
            "[256,    20] loss: 0.010\n",
            "[256,    40] loss: 0.014\n",
            "[256,    60] loss: 0.009\n",
            "[256,    80] loss: 0.056\n",
            "[256,   100] loss: 0.015\n",
            "[256,   120] loss: 0.021\n",
            "0.9125300315869329\n",
            "SpearmanrResult(correlation=0.6678891203917815, pvalue=1.7567744077380316e-56)\n",
            "[257,    20] loss: 0.018\n",
            "[257,    40] loss: 0.018\n",
            "[257,    60] loss: 0.018\n",
            "[257,    80] loss: 0.020\n",
            "[257,   100] loss: 0.015\n",
            "[257,   120] loss: 0.023\n",
            "[258,    20] loss: 0.014\n",
            "[258,    40] loss: 0.022\n",
            "[258,    60] loss: 0.024\n",
            "[258,    80] loss: 0.025\n",
            "[258,   100] loss: 0.016\n",
            "[258,   120] loss: 0.019\n",
            "[259,    20] loss: 0.011\n",
            "[259,    40] loss: 0.037\n",
            "[259,    60] loss: 0.020\n",
            "[259,    80] loss: 0.045\n",
            "[259,   100] loss: 0.024\n",
            "[259,   120] loss: 0.014\n",
            "[260,    20] loss: 0.014\n",
            "[260,    40] loss: 0.011\n",
            "[260,    60] loss: 0.020\n",
            "[260,    80] loss: 0.008\n",
            "[260,   100] loss: 0.010\n",
            "[260,   120] loss: 0.041\n",
            "0.9142351027538748\n",
            "SpearmanrResult(correlation=0.6798186416284869, pvalue=3.3024759015081234e-59)\n",
            "[261,    20] loss: 0.038\n",
            "[261,    40] loss: 0.054\n",
            "[261,    60] loss: 0.034\n",
            "[261,    80] loss: 0.019\n",
            "[261,   100] loss: 0.015\n",
            "[261,   120] loss: 0.015\n",
            "[262,    20] loss: 0.024\n",
            "[262,    40] loss: 0.008\n",
            "[262,    60] loss: 0.020\n",
            "[262,    80] loss: 0.024\n",
            "[262,   100] loss: 0.020\n",
            "[262,   120] loss: 0.013\n",
            "[263,    20] loss: 0.018\n",
            "[263,    40] loss: 0.010\n",
            "[263,    60] loss: 0.013\n",
            "[263,    80] loss: 0.016\n",
            "[263,   100] loss: 0.006\n",
            "[263,   120] loss: 0.031\n",
            "[264,    20] loss: 0.027\n",
            "[264,    40] loss: 0.017\n",
            "[264,    60] loss: 0.015\n",
            "[264,    80] loss: 0.011\n",
            "[264,   100] loss: 0.028\n",
            "[264,   120] loss: 0.012\n",
            "0.9112515990480503\n",
            "SpearmanrResult(correlation=0.6989917568514185, pvalue=7.169895130278125e-64)\n",
            "[265,    20] loss: 0.008\n",
            "[265,    40] loss: 0.012\n",
            "[265,    60] loss: 0.083\n",
            "[265,    80] loss: 0.012\n",
            "[265,   100] loss: 0.031\n",
            "[265,   120] loss: 0.012\n",
            "[266,    20] loss: 0.023\n",
            "[266,    40] loss: 0.097\n",
            "[266,    60] loss: 0.013\n",
            "[266,    80] loss: 0.036\n",
            "[266,   100] loss: 0.013\n",
            "[266,   120] loss: 0.031\n",
            "[267,    20] loss: 0.014\n",
            "[267,    40] loss: 0.039\n",
            "[267,    60] loss: 0.021\n",
            "[267,    80] loss: 0.061\n",
            "[267,   100] loss: 0.035\n",
            "[267,   120] loss: 0.011\n",
            "[268,    20] loss: 0.031\n",
            "[268,    40] loss: 0.025\n",
            "[268,    60] loss: 0.035\n",
            "[268,    80] loss: 0.018\n",
            "[268,   100] loss: 0.017\n",
            "[268,   120] loss: 0.032\n",
            "0.9056519275098726\n",
            "SpearmanrResult(correlation=0.7171191261811866, pvalue=1.235365896057006e-68)\n",
            "[269,    20] loss: 0.085\n",
            "[269,    40] loss: 0.034\n",
            "[269,    60] loss: 0.026\n",
            "[269,    80] loss: 0.027\n",
            "[269,   100] loss: 0.012\n",
            "[269,   120] loss: 0.017\n",
            "[270,    20] loss: 0.025\n",
            "[270,    40] loss: 0.049\n",
            "[270,    60] loss: 0.027\n",
            "[270,    80] loss: 0.016\n",
            "[270,   100] loss: 0.019\n",
            "[270,   120] loss: 0.050\n",
            "[271,    20] loss: 0.007\n",
            "[271,    40] loss: 0.025\n",
            "[271,    60] loss: 0.031\n",
            "[271,    80] loss: 0.018\n",
            "[271,   100] loss: 0.016\n",
            "[271,   120] loss: 0.018\n",
            "[272,    20] loss: 0.028\n",
            "[272,    40] loss: 0.019\n",
            "[272,    60] loss: 0.015\n",
            "[272,    80] loss: 0.027\n",
            "[272,   100] loss: 0.037\n",
            "[272,   120] loss: 0.023\n",
            "0.9091423178325362\n",
            "SpearmanrResult(correlation=0.7093782274187609, pvalue=1.4823675829756929e-66)\n",
            "[273,    20] loss: 0.034\n",
            "[273,    40] loss: 0.027\n",
            "[273,    60] loss: 0.028\n",
            "[273,    80] loss: 0.015\n",
            "[273,   100] loss: 0.022\n",
            "[273,   120] loss: 0.026\n",
            "[274,    20] loss: 0.013\n",
            "[274,    40] loss: 0.018\n",
            "[274,    60] loss: 0.015\n",
            "[274,    80] loss: 0.010\n",
            "[274,   100] loss: 0.016\n",
            "[274,   120] loss: 0.027\n",
            "[275,    20] loss: 0.009\n",
            "[275,    40] loss: 0.030\n",
            "[275,    60] loss: 0.020\n",
            "[275,    80] loss: 0.018\n",
            "[275,   100] loss: 0.009\n",
            "[275,   120] loss: 0.010\n",
            "[276,    20] loss: 0.017\n",
            "[276,    40] loss: 0.013\n",
            "[276,    60] loss: 0.010\n",
            "[276,    80] loss: 0.015\n",
            "[276,   100] loss: 0.038\n",
            "[276,   120] loss: 0.024\n",
            "0.9120115277883557\n",
            "SpearmanrResult(correlation=0.7126263892452886, pvalue=2.0273105092272946e-67)\n",
            "[277,    20] loss: 0.029\n",
            "[277,    40] loss: 0.023\n",
            "[277,    60] loss: 0.019\n",
            "[277,    80] loss: 0.011\n",
            "[277,   100] loss: 0.009\n",
            "[277,   120] loss: 0.019\n",
            "[278,    20] loss: 0.020\n",
            "[278,    40] loss: 0.017\n",
            "[278,    60] loss: 0.009\n",
            "[278,    80] loss: 0.011\n",
            "[278,   100] loss: 0.019\n",
            "[278,   120] loss: 0.015\n",
            "[279,    20] loss: 0.019\n",
            "[279,    40] loss: 0.022\n",
            "[279,    60] loss: 0.010\n",
            "[279,    80] loss: 0.012\n",
            "[279,   100] loss: 0.017\n",
            "[279,   120] loss: 0.044\n",
            "[280,    20] loss: 0.023\n",
            "[280,    40] loss: 0.010\n",
            "[280,    60] loss: 0.013\n",
            "[280,    80] loss: 0.027\n",
            "[280,   100] loss: 0.014\n",
            "[280,   120] loss: 0.017\n",
            "0.9122440032824547\n",
            "SpearmanrResult(correlation=0.7193407761762581, pvalue=3.03483220946522e-69)\n",
            "[281,    20] loss: 0.017\n",
            "[281,    40] loss: 0.017\n",
            "[281,    60] loss: 0.029\n",
            "[281,    80] loss: 0.017\n",
            "[281,   100] loss: 0.010\n",
            "[281,   120] loss: 0.015\n",
            "[282,    20] loss: 0.027\n",
            "[282,    40] loss: 0.024\n",
            "[282,    60] loss: 0.016\n",
            "[282,    80] loss: 0.010\n",
            "[282,   100] loss: 0.007\n",
            "[282,   120] loss: 0.024\n",
            "[283,    20] loss: 0.035\n",
            "[283,    40] loss: 0.051\n",
            "[283,    60] loss: 0.021\n",
            "[283,    80] loss: 0.018\n",
            "[283,   100] loss: 0.014\n",
            "[283,   120] loss: 0.015\n",
            "[284,    20] loss: 0.026\n",
            "[284,    40] loss: 0.040\n",
            "[284,    60] loss: 0.010\n",
            "[284,    80] loss: 0.027\n",
            "[284,   100] loss: 0.015\n",
            "[284,   120] loss: 0.038\n",
            "0.8975106864206202\n",
            "SpearmanrResult(correlation=0.7012161104294612, pvalue=1.9515697236849533e-64)\n",
            "[285,    20] loss: 0.024\n",
            "[285,    40] loss: 0.015\n",
            "[285,    60] loss: 0.045\n",
            "[285,    80] loss: 0.030\n",
            "[285,   100] loss: 0.015\n",
            "[285,   120] loss: 0.019\n",
            "[286,    20] loss: 0.038\n",
            "[286,    40] loss: 0.026\n",
            "[286,    60] loss: 0.026\n",
            "[286,    80] loss: 0.051\n",
            "[286,   100] loss: 0.017\n",
            "[286,   120] loss: 0.019\n",
            "[287,    20] loss: 0.022\n",
            "[287,    40] loss: 0.025\n",
            "[287,    60] loss: 0.029\n",
            "[287,    80] loss: 0.017\n",
            "[287,   100] loss: 0.023\n",
            "[287,   120] loss: 0.033\n",
            "[288,    20] loss: 0.021\n",
            "[288,    40] loss: 0.018\n",
            "[288,    60] loss: 0.025\n",
            "[288,    80] loss: 0.045\n",
            "[288,   100] loss: 0.036\n",
            "[288,   120] loss: 0.106\n",
            "0.899107044807742\n",
            "SpearmanrResult(correlation=0.6628020586736408, pvalue=2.338727506319393e-55)\n",
            "[289,    20] loss: 0.035\n",
            "[289,    40] loss: 0.020\n",
            "[289,    60] loss: 0.023\n",
            "[289,    80] loss: 0.021\n",
            "[289,   100] loss: 0.016\n",
            "[289,   120] loss: 0.008\n",
            "[290,    20] loss: 0.040\n",
            "[290,    40] loss: 0.017\n",
            "[290,    60] loss: 0.008\n",
            "[290,    80] loss: 0.016\n",
            "[290,   100] loss: 0.014\n",
            "[290,   120] loss: 0.057\n",
            "[291,    20] loss: 0.024\n",
            "[291,    40] loss: 0.018\n",
            "[291,    60] loss: 0.034\n",
            "[291,    80] loss: 0.053\n",
            "[291,   100] loss: 0.017\n",
            "[291,   120] loss: 0.040\n",
            "[292,    20] loss: 0.078\n",
            "[292,    40] loss: 0.057\n",
            "[292,    60] loss: 0.038\n",
            "[292,    80] loss: 0.042\n",
            "[292,   100] loss: 0.019\n",
            "[292,   120] loss: 0.035\n",
            "0.8997322102401726\n",
            "SpearmanrResult(correlation=0.7114679425648501, pvalue=4.134775541935229e-67)\n",
            "[293,    20] loss: 0.032\n",
            "[293,    40] loss: 0.078\n",
            "[293,    60] loss: 0.021\n",
            "[293,    80] loss: 0.023\n",
            "[293,   100] loss: 0.015\n",
            "[293,   120] loss: 0.045\n",
            "[294,    20] loss: 0.056\n",
            "[294,    40] loss: 0.098\n",
            "[294,    60] loss: 0.031\n",
            "[294,    80] loss: 0.032\n",
            "[294,   100] loss: 0.022\n",
            "[294,   120] loss: 0.023\n",
            "[295,    20] loss: 0.020\n",
            "[295,    40] loss: 0.029\n",
            "[295,    60] loss: 0.038\n",
            "[295,    80] loss: 0.240\n",
            "[295,   100] loss: 0.042\n",
            "[295,   120] loss: 0.056\n",
            "[296,    20] loss: 0.029\n",
            "[296,    40] loss: 0.016\n",
            "[296,    60] loss: 0.036\n",
            "[296,    80] loss: 0.040\n",
            "[296,   100] loss: 0.052\n",
            "[296,   120] loss: 0.035\n",
            "0.8852681710380896\n",
            "SpearmanrResult(correlation=0.7262692096332993, pvalue=3.4859679730441175e-71)\n",
            "[297,    20] loss: 0.037\n",
            "[297,    40] loss: 0.137\n",
            "[297,    60] loss: 0.040\n",
            "[297,    80] loss: 0.036\n",
            "[297,   100] loss: 0.054\n",
            "[297,   120] loss: 0.026\n",
            "[298,    20] loss: 0.041\n",
            "[298,    40] loss: 0.030\n",
            "[298,    60] loss: 0.037\n",
            "[298,    80] loss: 0.015\n",
            "[298,   100] loss: 0.027\n",
            "[298,   120] loss: 0.010\n",
            "[299,    20] loss: 0.047\n",
            "[299,    40] loss: 0.031\n",
            "[299,    60] loss: 0.031\n",
            "[299,    80] loss: 0.022\n",
            "[299,   100] loss: 0.040\n",
            "[299,   120] loss: 0.012\n",
            "[300,    20] loss: 0.025\n",
            "[300,    40] loss: 0.018\n",
            "[300,    60] loss: 0.013\n",
            "[300,    80] loss: 0.032\n",
            "[300,   100] loss: 0.035\n",
            "[300,   120] loss: 0.015\n",
            "0.9009225287127631\n",
            "SpearmanrResult(correlation=0.6792407700797533, pvalue=4.506765853516454e-59)\n",
            "[301,    20] loss: 0.012\n",
            "[301,    40] loss: 0.016\n",
            "[301,    60] loss: 0.022\n",
            "[301,    80] loss: 0.042\n",
            "[301,   100] loss: 0.014\n",
            "[301,   120] loss: 0.020\n",
            "[302,    20] loss: 0.013\n",
            "[302,    40] loss: 0.014\n",
            "[302,    60] loss: 0.006\n",
            "[302,    80] loss: 0.021\n",
            "[302,   100] loss: 0.019\n",
            "[302,   120] loss: 0.017\n",
            "[303,    20] loss: 0.064\n",
            "[303,    40] loss: 0.046\n",
            "[303,    60] loss: 0.005\n",
            "[303,    80] loss: 0.011\n",
            "[303,   100] loss: 0.015\n",
            "[303,   120] loss: 0.018\n",
            "[304,    20] loss: 0.009\n",
            "[304,    40] loss: 0.015\n",
            "[304,    60] loss: 0.026\n",
            "[304,    80] loss: 0.022\n",
            "[304,   100] loss: 0.007\n",
            "[304,   120] loss: 0.034\n",
            "0.9060294315929222\n",
            "SpearmanrResult(correlation=0.7257770030421308, pvalue=4.809443604856318e-71)\n",
            "[305,    20] loss: 0.027\n",
            "[305,    40] loss: 0.011\n",
            "[305,    60] loss: 0.010\n",
            "[305,    80] loss: 0.025\n",
            "[305,   100] loss: 0.025\n",
            "[305,   120] loss: 0.021\n",
            "[306,    20] loss: 0.012\n",
            "[306,    40] loss: 0.015\n",
            "[306,    60] loss: 0.046\n",
            "[306,    80] loss: 0.023\n",
            "[306,   100] loss: 0.019\n",
            "[306,   120] loss: 0.019\n",
            "[307,    20] loss: 0.010\n",
            "[307,    40] loss: 0.020\n",
            "[307,    60] loss: 0.024\n",
            "[307,    80] loss: 0.011\n",
            "[307,   100] loss: 0.009\n",
            "[307,   120] loss: 0.015\n",
            "[308,    20] loss: 0.008\n",
            "[308,    40] loss: 0.009\n",
            "[308,    60] loss: 0.035\n",
            "[308,    80] loss: 0.013\n",
            "[308,   100] loss: 0.008\n",
            "[308,   120] loss: 0.044\n",
            "0.9018381380229914\n",
            "SpearmanrResult(correlation=0.7222168477407553, pvalue=4.8312927630567174e-70)\n",
            "[309,    20] loss: 0.025\n",
            "[309,    40] loss: 0.020\n",
            "[309,    60] loss: 0.009\n",
            "[309,    80] loss: 0.015\n",
            "[309,   100] loss: 0.013\n",
            "[309,   120] loss: 0.013\n",
            "[310,    20] loss: 0.008\n",
            "[310,    40] loss: 0.016\n",
            "[310,    60] loss: 0.020\n",
            "[310,    80] loss: 0.027\n",
            "[310,   100] loss: 0.009\n",
            "[310,   120] loss: 0.023\n",
            "[311,    20] loss: 0.010\n",
            "[311,    40] loss: 0.014\n",
            "[311,    60] loss: 0.012\n",
            "[311,    80] loss: 0.026\n",
            "[311,   100] loss: 0.016\n",
            "[311,   120] loss: 0.011\n",
            "[312,    20] loss: 0.010\n",
            "[312,    40] loss: 0.007\n",
            "[312,    60] loss: 0.028\n",
            "[312,    80] loss: 0.015\n",
            "[312,   100] loss: 0.009\n",
            "[312,   120] loss: 0.007\n",
            "0.902500258613708\n",
            "SpearmanrResult(correlation=0.7326031638176423, pvalue=5.200119801663974e-73)\n",
            "[313,    20] loss: 0.012\n",
            "[313,    40] loss: 0.005\n",
            "[313,    60] loss: 0.008\n",
            "[313,    80] loss: 0.012\n",
            "[313,   100] loss: 0.006\n",
            "[313,   120] loss: 0.016\n",
            "[314,    20] loss: 0.011\n",
            "[314,    40] loss: 0.025\n",
            "[314,    60] loss: 0.010\n",
            "[314,    80] loss: 0.011\n",
            "[314,   100] loss: 0.017\n",
            "[314,   120] loss: 0.014\n",
            "[315,    20] loss: 0.015\n",
            "[315,    40] loss: 0.044\n",
            "[315,    60] loss: 0.014\n",
            "[315,    80] loss: 0.012\n",
            "[315,   100] loss: 0.031\n",
            "[315,   120] loss: 0.036\n",
            "[316,    20] loss: 0.014\n",
            "[316,    40] loss: 0.020\n",
            "[316,    60] loss: 0.007\n",
            "[316,    80] loss: 0.013\n",
            "[316,   100] loss: 0.055\n",
            "[316,   120] loss: 0.020\n",
            "0.9035880067904224\n",
            "SpearmanrResult(correlation=0.752691326008399, pvalue=3.6380241074154066e-79)\n",
            "[317,    20] loss: 0.040\n",
            "[317,    40] loss: 0.035\n",
            "[317,    60] loss: 0.010\n",
            "[317,    80] loss: 0.018\n",
            "[317,   100] loss: 0.022\n",
            "[317,   120] loss: 0.020\n",
            "[318,    20] loss: 0.018\n",
            "[318,    40] loss: 0.019\n",
            "[318,    60] loss: 0.010\n",
            "[318,    80] loss: 0.069\n",
            "[318,   100] loss: 0.051\n",
            "[318,   120] loss: 0.026\n",
            "[319,    20] loss: 0.018\n",
            "[319,    40] loss: 0.010\n",
            "[319,    60] loss: 0.021\n",
            "[319,    80] loss: 0.016\n",
            "[319,   100] loss: 0.012\n",
            "[319,   120] loss: 0.017\n",
            "[320,    20] loss: 0.016\n",
            "[320,    40] loss: 0.011\n",
            "[320,    60] loss: 0.006\n",
            "[320,    80] loss: 0.008\n",
            "[320,   100] loss: 0.010\n",
            "[320,   120] loss: 0.016\n",
            "0.8890734503557068\n",
            "SpearmanrResult(correlation=0.7103508993264811, pvalue=8.193563072012849e-67)\n",
            "[321,    20] loss: 0.007\n",
            "[321,    40] loss: 0.011\n",
            "[321,    60] loss: 0.015\n",
            "[321,    80] loss: 0.018\n",
            "[321,   100] loss: 0.018\n",
            "[321,   120] loss: 0.014\n",
            "[322,    20] loss: 0.029\n",
            "[322,    40] loss: 0.024\n",
            "[322,    60] loss: 0.022\n",
            "[322,    80] loss: 0.009\n",
            "[322,   100] loss: 0.006\n",
            "[322,   120] loss: 0.006\n",
            "[323,    20] loss: 0.014\n",
            "[323,    40] loss: 0.008\n",
            "[323,    60] loss: 0.010\n",
            "[323,    80] loss: 0.012\n",
            "[323,   100] loss: 0.007\n",
            "[323,   120] loss: 0.005\n",
            "[324,    20] loss: 0.007\n",
            "[324,    40] loss: 0.020\n",
            "[324,    60] loss: 0.028\n",
            "[324,    80] loss: 0.037\n",
            "[324,   100] loss: 0.017\n",
            "[324,   120] loss: 0.021\n",
            "0.8960892962804122\n",
            "SpearmanrResult(correlation=0.737889440978128, pvalue=1.416829359391414e-74)\n",
            "[325,    20] loss: 0.057\n",
            "[325,    40] loss: 0.026\n",
            "[325,    60] loss: 0.071\n",
            "[325,    80] loss: 0.035\n",
            "[325,   100] loss: 0.019\n",
            "[325,   120] loss: 0.020\n",
            "[326,    20] loss: 0.012\n",
            "[326,    40] loss: 0.025\n",
            "[326,    60] loss: 0.024\n",
            "[326,    80] loss: 0.024\n",
            "[326,   100] loss: 0.024\n",
            "[326,   120] loss: 0.012\n",
            "[327,    20] loss: 0.020\n",
            "[327,    40] loss: 0.014\n",
            "[327,    60] loss: 0.013\n",
            "[327,    80] loss: 0.012\n",
            "[327,   100] loss: 0.012\n",
            "[327,   120] loss: 0.007\n",
            "[328,    20] loss: 0.006\n",
            "[328,    40] loss: 0.020\n",
            "[328,    60] loss: 0.013\n",
            "[328,    80] loss: 0.012\n",
            "[328,   100] loss: 0.013\n",
            "[328,   120] loss: 0.014\n",
            "0.8995306470937624\n",
            "SpearmanrResult(correlation=0.7205347556614576, pvalue=1.4191877521803335e-69)\n",
            "[329,    20] loss: 0.007\n",
            "[329,    40] loss: 0.007\n",
            "[329,    60] loss: 0.018\n",
            "[329,    80] loss: 0.007\n",
            "[329,   100] loss: 0.017\n",
            "[329,   120] loss: 0.013\n",
            "[330,    20] loss: 0.026\n",
            "[330,    40] loss: 0.009\n",
            "[330,    60] loss: 0.019\n",
            "[330,    80] loss: 0.029\n",
            "[330,   100] loss: 0.011\n",
            "[330,   120] loss: 0.011\n",
            "[331,    20] loss: 0.020\n",
            "[331,    40] loss: 0.067\n",
            "[331,    60] loss: 0.010\n",
            "[331,    80] loss: 0.016\n",
            "[331,   100] loss: 0.005\n",
            "[331,   120] loss: 0.007\n",
            "[332,    20] loss: 0.010\n",
            "[332,    40] loss: 0.014\n",
            "[332,    60] loss: 0.011\n",
            "[332,    80] loss: 0.005\n",
            "[332,   100] loss: 0.011\n",
            "[332,   120] loss: 0.030\n",
            "0.901520728388314\n",
            "SpearmanrResult(correlation=0.6586169894798372, pvalue=1.8944903161550302e-54)\n",
            "[333,    20] loss: 0.139\n",
            "[333,    40] loss: 0.080\n",
            "[333,    60] loss: 0.043\n",
            "[333,    80] loss: 0.040\n",
            "[333,   100] loss: 0.025\n",
            "[333,   120] loss: 0.021\n",
            "[334,    20] loss: 0.018\n",
            "[334,    40] loss: 0.015\n",
            "[334,    60] loss: 0.023\n",
            "[334,    80] loss: 0.023\n",
            "[334,   100] loss: 0.019\n",
            "[334,   120] loss: 0.012\n",
            "[335,    20] loss: 0.021\n",
            "[335,    40] loss: 0.016\n",
            "[335,    60] loss: 0.023\n",
            "[335,    80] loss: 0.009\n",
            "[335,   100] loss: 0.011\n",
            "[335,   120] loss: 0.023\n",
            "[336,    20] loss: 0.056\n",
            "[336,    40] loss: 0.052\n",
            "[336,    60] loss: 0.019\n",
            "[336,    80] loss: 0.021\n",
            "[336,   100] loss: 0.025\n",
            "[336,   120] loss: 0.022\n",
            "0.8956621276124233\n",
            "SpearmanrResult(correlation=0.7052503969387136, pvalue=1.7861583362918403e-65)\n",
            "[337,    20] loss: 0.019\n",
            "[337,    40] loss: 0.017\n",
            "[337,    60] loss: 0.009\n",
            "[337,    80] loss: 0.016\n",
            "[337,   100] loss: 0.029\n",
            "[337,   120] loss: 0.020\n",
            "[338,    20] loss: 0.014\n",
            "[338,    40] loss: 0.055\n",
            "[338,    60] loss: 0.028\n",
            "[338,    80] loss: 0.008\n",
            "[338,   100] loss: 0.028\n",
            "[338,   120] loss: 0.012\n",
            "[339,    20] loss: 0.006\n",
            "[339,    40] loss: 0.008\n",
            "[339,    60] loss: 0.009\n",
            "[339,    80] loss: 0.032\n",
            "[339,   100] loss: 0.015\n",
            "[339,   120] loss: 0.017\n",
            "[340,    20] loss: 0.010\n",
            "[340,    40] loss: 0.008\n",
            "[340,    60] loss: 0.018\n",
            "[340,    80] loss: 0.019\n",
            "[340,   100] loss: 0.008\n",
            "[340,   120] loss: 0.007\n",
            "0.8854496108419131\n",
            "SpearmanrResult(correlation=0.6764185384389918, pvalue=2.0364347539757878e-58)\n",
            "[341,    20] loss: 0.007\n",
            "[341,    40] loss: 0.031\n",
            "[341,    60] loss: 0.006\n",
            "[341,    80] loss: 0.007\n",
            "[341,   100] loss: 0.010\n",
            "[341,   120] loss: 0.009\n",
            "[342,    20] loss: 0.021\n",
            "[342,    40] loss: 0.014\n",
            "[342,    60] loss: 0.009\n",
            "[342,    80] loss: 0.012\n",
            "[342,   100] loss: 0.010\n",
            "[342,   120] loss: 0.006\n",
            "[343,    20] loss: 0.008\n",
            "[343,    40] loss: 0.015\n",
            "[343,    60] loss: 0.014\n",
            "[343,    80] loss: 0.014\n",
            "[343,   100] loss: 0.010\n",
            "[343,   120] loss: 0.014\n",
            "[344,    20] loss: 0.009\n",
            "[344,    40] loss: 0.015\n",
            "[344,    60] loss: 0.013\n",
            "[344,    80] loss: 0.009\n",
            "[344,   100] loss: 0.017\n",
            "[344,   120] loss: 0.020\n",
            "0.8996142981964782\n",
            "SpearmanrResult(correlation=0.682260363277394, pvalue=8.807623741834111e-60)\n",
            "[345,    20] loss: 0.021\n",
            "[345,    40] loss: 0.010\n",
            "[345,    60] loss: 0.007\n",
            "[345,    80] loss: 0.020\n",
            "[345,   100] loss: 0.031\n",
            "[345,   120] loss: 0.010\n",
            "[346,    20] loss: 0.021\n",
            "[346,    40] loss: 0.011\n",
            "[346,    60] loss: 0.009\n",
            "[346,    80] loss: 0.010\n",
            "[346,   100] loss: 0.008\n",
            "[346,   120] loss: 0.006\n",
            "[347,    20] loss: 0.011\n",
            "[347,    40] loss: 0.010\n",
            "[347,    60] loss: 0.007\n",
            "[347,    80] loss: 0.009\n",
            "[347,   100] loss: 0.018\n",
            "[347,   120] loss: 0.009\n",
            "[348,    20] loss: 0.011\n",
            "[348,    40] loss: 0.017\n",
            "[348,    60] loss: 0.014\n",
            "[348,    80] loss: 0.027\n",
            "[348,   100] loss: 0.010\n",
            "[348,   120] loss: 0.011\n",
            "0.8962745403885013\n",
            "SpearmanrResult(correlation=0.6902282857641516, pvalue=1.0768385337802063e-61)\n",
            "[349,    20] loss: 0.012\n",
            "[349,    40] loss: 0.009\n",
            "[349,    60] loss: 0.020\n",
            "[349,    80] loss: 0.022\n",
            "[349,   100] loss: 0.007\n",
            "[349,   120] loss: 0.013\n",
            "[350,    20] loss: 0.008\n",
            "[350,    40] loss: 0.013\n",
            "[350,    60] loss: 0.013\n",
            "[350,    80] loss: 0.013\n",
            "[350,   100] loss: 0.014\n",
            "[350,   120] loss: 0.007\n",
            "[351,    20] loss: 0.009\n",
            "[351,    40] loss: 0.020\n",
            "[351,    60] loss: 0.029\n",
            "[351,    80] loss: 0.012\n",
            "[351,   100] loss: 0.025\n",
            "[351,   120] loss: 0.049\n",
            "[352,    20] loss: 0.011\n",
            "[352,    40] loss: 0.010\n",
            "[352,    60] loss: 0.009\n",
            "[352,    80] loss: 0.008\n",
            "[352,   100] loss: 0.013\n",
            "[352,   120] loss: 0.028\n",
            "0.885762726974372\n",
            "SpearmanrResult(correlation=0.736196380076491, pvalue=4.534772537212322e-74)\n",
            "[353,    20] loss: 0.013\n",
            "[353,    40] loss: 0.015\n",
            "[353,    60] loss: 0.007\n",
            "[353,    80] loss: 0.012\n",
            "[353,   100] loss: 0.019\n",
            "[353,   120] loss: 0.030\n",
            "[354,    20] loss: 0.005\n",
            "[354,    40] loss: 0.031\n",
            "[354,    60] loss: 0.016\n",
            "[354,    80] loss: 0.014\n",
            "[354,   100] loss: 0.021\n",
            "[354,   120] loss: 0.011\n",
            "[355,    20] loss: 0.009\n",
            "[355,    40] loss: 0.029\n",
            "[355,    60] loss: 0.018\n",
            "[355,    80] loss: 0.013\n",
            "[355,   100] loss: 0.017\n",
            "[355,   120] loss: 0.017\n",
            "[356,    20] loss: 0.010\n",
            "[356,    40] loss: 0.026\n",
            "[356,    60] loss: 0.019\n",
            "[356,    80] loss: 0.029\n",
            "[356,   100] loss: 0.029\n",
            "[356,   120] loss: 0.012\n",
            "0.8826189293990859\n",
            "SpearmanrResult(correlation=0.725589915100541, pvalue=5.434280648563971e-71)\n",
            "[357,    20] loss: 0.017\n",
            "[357,    40] loss: 0.039\n",
            "[357,    60] loss: 0.036\n",
            "[357,    80] loss: 0.013\n",
            "[357,   100] loss: 0.027\n",
            "[357,   120] loss: 0.008\n",
            "[358,    20] loss: 0.025\n",
            "[358,    40] loss: 0.010\n",
            "[358,    60] loss: 0.008\n",
            "[358,    80] loss: 0.024\n",
            "[358,   100] loss: 0.016\n",
            "[358,   120] loss: 0.016\n",
            "[359,    20] loss: 0.020\n",
            "[359,    40] loss: 0.017\n",
            "[359,    60] loss: 0.020\n",
            "[359,    80] loss: 0.037\n",
            "[359,   100] loss: 0.063\n",
            "[359,   120] loss: 0.027\n",
            "[360,    20] loss: 0.011\n",
            "[360,    40] loss: 0.011\n",
            "[360,    60] loss: 0.017\n",
            "[360,    80] loss: 0.023\n",
            "[360,   100] loss: 0.027\n",
            "[360,   120] loss: 0.021\n",
            "0.895419967757256\n",
            "SpearmanrResult(correlation=0.7109252175947389, pvalue=5.766853817025369e-67)\n",
            "[361,    20] loss: 0.028\n",
            "[361,    40] loss: 0.012\n",
            "[361,    60] loss: 0.009\n",
            "[361,    80] loss: 0.008\n",
            "[361,   100] loss: 0.008\n",
            "[361,   120] loss: 0.015\n",
            "[362,    20] loss: 0.017\n",
            "[362,    40] loss: 0.016\n",
            "[362,    60] loss: 0.007\n",
            "[362,    80] loss: 0.015\n",
            "[362,   100] loss: 0.048\n",
            "[362,   120] loss: 0.043\n",
            "[363,    20] loss: 0.011\n",
            "[363,    40] loss: 0.006\n",
            "[363,    60] loss: 0.014\n",
            "[363,    80] loss: 0.010\n",
            "[363,   100] loss: 0.025\n",
            "[363,   120] loss: 0.036\n",
            "[364,    20] loss: 0.017\n",
            "[364,    40] loss: 0.014\n",
            "[364,    60] loss: 0.005\n",
            "[364,    80] loss: 0.012\n",
            "[364,   100] loss: 0.017\n",
            "[364,   120] loss: 0.010\n",
            "0.9057756386585502\n",
            "SpearmanrResult(correlation=0.742008697237896, pvalue=8.044962604958622e-76)\n",
            "[365,    20] loss: 0.014\n",
            "[365,    40] loss: 0.051\n",
            "[365,    60] loss: 0.019\n",
            "[365,    80] loss: 0.018\n",
            "[365,   100] loss: 0.033\n",
            "[365,   120] loss: 0.014\n",
            "[366,    20] loss: 0.010\n",
            "[366,    40] loss: 0.013\n",
            "[366,    60] loss: 0.015\n",
            "[366,    80] loss: 0.018\n",
            "[366,   100] loss: 0.021\n",
            "[366,   120] loss: 0.041\n",
            "[367,    20] loss: 0.020\n",
            "[367,    40] loss: 0.016\n",
            "[367,    60] loss: 0.008\n",
            "[367,    80] loss: 0.024\n",
            "[367,   100] loss: 0.018\n",
            "[367,   120] loss: 0.036\n",
            "[368,    20] loss: 0.015\n",
            "[368,    40] loss: 0.013\n",
            "[368,    60] loss: 0.020\n",
            "[368,    80] loss: 0.047\n",
            "[368,   100] loss: 0.008\n",
            "[368,   120] loss: 0.016\n",
            "0.9030784866714588\n",
            "SpearmanrResult(correlation=0.7182831345180224, pvalue=5.930687260186553e-69)\n",
            "[369,    20] loss: 0.012\n",
            "[369,    40] loss: 0.018\n",
            "[369,    60] loss: 0.010\n",
            "[369,    80] loss: 0.058\n",
            "[369,   100] loss: 0.014\n",
            "[369,   120] loss: 0.034\n",
            "[370,    20] loss: 0.016\n",
            "[370,    40] loss: 0.022\n",
            "[370,    60] loss: 0.025\n",
            "[370,    80] loss: 0.012\n",
            "[370,   100] loss: 0.012\n",
            "[370,   120] loss: 0.008\n",
            "[371,    20] loss: 0.018\n",
            "[371,    40] loss: 0.013\n",
            "[371,    60] loss: 0.018\n",
            "[371,    80] loss: 0.067\n",
            "[371,   100] loss: 0.011\n",
            "[371,   120] loss: 0.029\n",
            "[372,    20] loss: 0.006\n",
            "[372,    40] loss: 0.009\n",
            "[372,    60] loss: 0.008\n",
            "[372,    80] loss: 0.006\n",
            "[372,   100] loss: 0.041\n",
            "[372,   120] loss: 0.018\n",
            "0.896562426667673\n",
            "SpearmanrResult(correlation=0.6760310763766407, pvalue=2.5016413365346125e-58)\n",
            "[373,    20] loss: 0.019\n",
            "[373,    40] loss: 0.018\n",
            "[373,    60] loss: 0.011\n",
            "[373,    80] loss: 0.019\n",
            "[373,   100] loss: 0.021\n",
            "[373,   120] loss: 0.024\n",
            "[374,    20] loss: 0.013\n",
            "[374,    40] loss: 0.014\n",
            "[374,    60] loss: 0.024\n",
            "[374,    80] loss: 0.020\n",
            "[374,   100] loss: 0.024\n",
            "[374,   120] loss: 0.012\n",
            "[375,    20] loss: 0.025\n",
            "[375,    40] loss: 0.008\n",
            "[375,    60] loss: 0.016\n",
            "[375,    80] loss: 0.058\n",
            "[375,   100] loss: 0.011\n",
            "[375,   120] loss: 0.017\n",
            "[376,    20] loss: 0.008\n",
            "[376,    40] loss: 0.015\n",
            "[376,    60] loss: 0.023\n",
            "[376,    80] loss: 0.015\n",
            "[376,   100] loss: 0.010\n",
            "[376,   120] loss: 0.013\n",
            "0.89475891811974\n",
            "SpearmanrResult(correlation=0.7251239718868047, pvalue=7.363180620659387e-71)\n",
            "[377,    20] loss: 0.021\n",
            "[377,    40] loss: 0.012\n",
            "[377,    60] loss: 0.019\n",
            "[377,    80] loss: 0.010\n",
            "[377,   100] loss: 0.013\n",
            "[377,   120] loss: 0.055\n",
            "[378,    20] loss: 0.012\n",
            "[378,    40] loss: 0.009\n",
            "[378,    60] loss: 0.011\n",
            "[378,    80] loss: 0.014\n",
            "[378,   100] loss: 0.123\n",
            "[378,   120] loss: 0.038\n",
            "[379,    20] loss: 0.063\n",
            "[379,    40] loss: 0.029\n",
            "[379,    60] loss: 0.021\n",
            "[379,    80] loss: 0.035\n",
            "[379,   100] loss: 0.014\n",
            "[379,   120] loss: 0.011\n",
            "[380,    20] loss: 0.013\n",
            "[380,    40] loss: 0.010\n",
            "[380,    60] loss: 0.022\n",
            "[380,    80] loss: 0.013\n",
            "[380,   100] loss: 0.010\n",
            "[380,   120] loss: 0.012\n",
            "0.893435561493912\n",
            "SpearmanrResult(correlation=0.6680517215961773, pvalue=1.6158944629372648e-56)\n",
            "[381,    20] loss: 0.007\n",
            "[381,    40] loss: 0.013\n",
            "[381,    60] loss: 0.014\n",
            "[381,    80] loss: 0.015\n",
            "[381,   100] loss: 0.016\n",
            "[381,   120] loss: 0.012\n",
            "[382,    20] loss: 0.019\n",
            "[382,    40] loss: 0.014\n",
            "[382,    60] loss: 0.017\n",
            "[382,    80] loss: 0.005\n",
            "[382,   100] loss: 0.011\n",
            "[382,   120] loss: 0.019\n",
            "[383,    20] loss: 0.009\n",
            "[383,    40] loss: 0.005\n",
            "[383,    60] loss: 0.015\n",
            "[383,    80] loss: 0.018\n",
            "[383,   100] loss: 0.021\n",
            "[383,   120] loss: 0.021\n",
            "[384,    20] loss: 0.012\n",
            "[384,    40] loss: 0.006\n",
            "[384,    60] loss: 0.005\n",
            "[384,    80] loss: 0.017\n",
            "[384,   100] loss: 0.015\n",
            "[384,   120] loss: 0.011\n",
            "0.9017824037763642\n",
            "SpearmanrResult(correlation=0.7129261007289255, pvalue=1.6849550913940203e-67)\n",
            "[385,    20] loss: 0.014\n",
            "[385,    40] loss: 0.013\n",
            "[385,    60] loss: 0.009\n",
            "[385,    80] loss: 0.010\n",
            "[385,   100] loss: 0.006\n",
            "[385,   120] loss: 0.007\n",
            "[386,    20] loss: 0.004\n",
            "[386,    40] loss: 0.007\n",
            "[386,    60] loss: 0.011\n",
            "[386,    80] loss: 0.005\n",
            "[386,   100] loss: 0.005\n",
            "[386,   120] loss: 0.056\n",
            "[387,    20] loss: 0.025\n",
            "[387,    40] loss: 0.016\n",
            "[387,    60] loss: 0.026\n",
            "[387,    80] loss: 0.014\n",
            "[387,   100] loss: 0.018\n",
            "[387,   120] loss: 0.010\n",
            "[388,    20] loss: 0.012\n",
            "[388,    40] loss: 0.009\n",
            "[388,    60] loss: 0.015\n",
            "[388,    80] loss: 0.020\n",
            "[388,   100] loss: 0.012\n",
            "[388,   120] loss: 0.009\n",
            "0.8965400472094736\n",
            "SpearmanrResult(correlation=0.7196563229315819, pvalue=2.483498389917041e-69)\n",
            "[389,    20] loss: 0.015\n",
            "[389,    40] loss: 0.041\n",
            "[389,    60] loss: 0.034\n",
            "[389,    80] loss: 0.030\n",
            "[389,   100] loss: 0.010\n",
            "[389,   120] loss: 0.017\n",
            "[390,    20] loss: 0.020\n",
            "[390,    40] loss: 0.021\n",
            "[390,    60] loss: 0.036\n",
            "[390,    80] loss: 0.018\n",
            "[390,   100] loss: 0.005\n",
            "[390,   120] loss: 0.010\n",
            "[391,    20] loss: 0.014\n",
            "[391,    40] loss: 0.016\n",
            "[391,    60] loss: 0.014\n",
            "[391,    80] loss: 0.007\n",
            "[391,   100] loss: 0.015\n",
            "[391,   120] loss: 0.012\n",
            "[392,    20] loss: 0.012\n",
            "[392,    40] loss: 0.008\n",
            "[392,    60] loss: 0.026\n",
            "[392,    80] loss: 0.031\n",
            "[392,   100] loss: 0.010\n",
            "[392,   120] loss: 0.006\n",
            "0.9038154772135238\n",
            "SpearmanrResult(correlation=0.7016593435462416, pvalue=1.5036518289121367e-64)\n",
            "[393,    20] loss: 0.013\n",
            "[393,    40] loss: 0.027\n",
            "[393,    60] loss: 0.022\n",
            "[393,    80] loss: 0.017\n",
            "[393,   100] loss: 0.009\n",
            "[393,   120] loss: 0.016\n",
            "[394,    20] loss: 0.008\n",
            "[394,    40] loss: 0.014\n",
            "[394,    60] loss: 0.010\n",
            "[394,    80] loss: 0.009\n",
            "[394,   100] loss: 0.010\n",
            "[394,   120] loss: 0.006\n",
            "[395,    20] loss: 0.006\n",
            "[395,    40] loss: 0.005\n",
            "[395,    60] loss: 0.009\n",
            "[395,    80] loss: 0.024\n",
            "[395,   100] loss: 0.021\n",
            "[395,   120] loss: 0.012\n",
            "[396,    20] loss: 0.010\n",
            "[396,    40] loss: 0.016\n",
            "[396,    60] loss: 0.023\n",
            "[396,    80] loss: 0.023\n",
            "[396,   100] loss: 0.011\n",
            "[396,   120] loss: 0.006\n",
            "0.8945625205996234\n",
            "SpearmanrResult(correlation=0.7008427069985591, pvalue=2.4300681878676172e-64)\n",
            "[397,    20] loss: 0.009\n",
            "[397,    40] loss: 0.009\n",
            "[397,    60] loss: 0.022\n",
            "[397,    80] loss: 0.009\n",
            "[397,   100] loss: 0.021\n",
            "[397,   120] loss: 0.004\n",
            "[398,    20] loss: 0.017\n",
            "[398,    40] loss: 0.009\n",
            "[398,    60] loss: 0.016\n",
            "[398,    80] loss: 0.017\n",
            "[398,   100] loss: 0.030\n",
            "[398,   120] loss: 0.005\n",
            "[399,    20] loss: 0.008\n",
            "[399,    40] loss: 0.015\n",
            "[399,    60] loss: 0.017\n",
            "[399,    80] loss: 0.016\n",
            "[399,   100] loss: 0.012\n",
            "[399,   120] loss: 0.008\n",
            "[400,    20] loss: 0.022\n",
            "[400,    40] loss: 0.014\n",
            "[400,    60] loss: 0.012\n",
            "[400,    80] loss: 0.011\n",
            "[400,   100] loss: 0.012\n",
            "[400,   120] loss: 0.012\n",
            "0.9036212057098972\n",
            "SpearmanrResult(correlation=0.7279418005495848, pvalue=1.1616316849762738e-71)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"  \\ntorch.save(model.state_dict,PATH+'efficientnetb0test/'+experiment+'regmodel{}.pt'.format(trainedepochs+epochs))\\ntorch.save(optimizer.state_dict, PATH+'efficientnetb0test/'+experiment+'regoptimizer{}.pt'.format(trainedepochs+epochs))\\nprint('Finished Training')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYrwJvJlbGMk"
      },
      "source": [
        "x=np.loadtxt(PATH+'batsize8_0.9036212057098972_pred399_norm_nopatch_b0.txt')\r\n",
        "y=np.loadtxt(PATH+'lab.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLJhp-_y384r",
        "outputId": "55c65325-fa61-4941-bed9-56e7f39aa5d5"
      },
      "source": [
        "stats.spearmanr(x1,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SpearmanrResult(correlation=0.7009007954098205, pvalue=2.3486217772876217e-64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwEaP3-4bPEY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "460dfe16-7b77-440b-bebf-db8e2ab8a153"
      },
      "source": [
        "plt.plot(x,y,'o')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7efb35475e90>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAV8klEQVR4nO3df4wc9XnH8c/j80I3BOXs4rj21Y4bhC4icsH0FGhJo6SkmKAqXGiaxk0bt0GyooYqRNQVTqSIVEiQuEmlVlEqUlBolVInxTikInUoQUKNEqdnbLAdcA0RFM7GdgoXkrJVjuPpHzt7rPdmdmd2d358794v6XR7M9+deXZm77m57zz7/Zq7CwAQnmVlBwAA6A8JHAACRQIHgECRwAEgUCRwAAjU8iJ3dt555/mGDRuK3CUABG///v0/dvdVncsLTeAbNmzQ1NRUkbsEgOCZ2TNxy+lCAYBAkcABIFAkcAAIFAkcAAJFAgeAQBVahQIUac+Bae3ce1THZxpaO1rX9s3jmtw0VnZYwcnjOA5jm2Wd36z7zTNOEjgWpT0HprVj9yE1ZuckSdMzDe3YfUiSSOIZ5HEch7HNss5v1v3mHSddKFiUdu49Ov9L09KYndPOvUdLiihMeRzHYWyzrPObdb95x0kCx6J0fKaRaTni5XEch7HNss5v1v3mHScJHIvS2tF6puWIl8dxHMY2yzq/Wfebd5wkcCxK2zePq14bOWNZvTai7ZvHS4ooTHkcx2Fss6zzm3W/ecfJTUwsSq0bRFShDCaP4ziMbZZ1frPuN+84rcg5MScmJpzBrAAgGzPb7+4TncvpQgGAQJHAASBQJHAACBQJHAACRQIHgECRwAEgUCRwAAgUCRwAAkUCB4BAkcABIFAkcAAIFAkcAALVM4Gb2Toze8jMfmhmR8zs49HylWb2gJkdi76vyD9cAEBLmivwVyTd6O4XSrpM0sfM7EJJN0l60N0vkPRg9DMAoCA9E7i7n3D3R6LHP5X0uKQxSddIuitqdpekybyCBAAslKkP3Mw2SNokaZ+k1e5+Ilr1vKTVCc/ZZmZTZjZ1+vTpAUIFALRLncDN7PWS7pF0g7u/1L7Om7NCxM4M4e63u/uEu0+sWrVqoGABAK9JlcDNrKZm8v6qu++OFp80szXR+jWSTuUTIgAgTpoqFJN0h6TH3f0Lbavuk7Q1erxV0jeGHx4AIEmaSY0vl/RHkg6Z2cFo2Scl3Sbpa2Z2naRnJH0gnxABAHF6JnB3/w9JlrD6iuGGAwBIi09iAkCgSOAAECgSOAAEigQOAIEigQNAoEjgABAoEjgABIoEDgCBIoEDQKBI4AAQKBI4AASKBA4AgSKBA0CgSOAAECgSOAAEigQOAIEigQNAoEjgABAoEjgABIoEDgCBIoEDQKBI4AAQKBI4AASKBA4AgVpedgDAUrPnwLR27j2q4zMNvaFek5k08/Ks1o7WtX3zuCY3jZUd4pLWfn6qfk5I4ECB9hyY1o7dh9SYnZMkzTRm59dNzzS0Y/chSapswljsOs9P1c8JXShAgXbuPTqfHOI0Zue0c+/RAiNCu7jzU+VzQgIHCnR8pjGUNshH0rGv6jkhgQMFWjtaH0ob5CPp2Ff1nJDAgQJt3zyuem0kcX29NqLtm8cLjAjt4s5Plc8JNzGBArVuhFGFUk2d56fq58TcvbCdTUxM+NTUVGH7A4DFwMz2u/tE53K6UAAgUCRwAAgUCRwAAkUCB4BA9UzgZnanmZ0ys8Nty242s2kzOxh9XZ1vmACATmmuwL8i6aqY5X/t7hdHX/cPNywAQC8968Dd/WEz25B/KACyqMKoeUXEkOc+qnAMBzHIB3muN7MPS5qSdKO7vxjXyMy2SdomSevXrx9gdwBaqjBqXhEx5LmPKhzDQfV7E/NLks6XdLGkE5I+n9TQ3W939wl3n1i1alWfuwPQrgqj5hURQ577qMIxHFRfCdzdT7r7nLu/KunLkt423LAAdFOFUfOKiCHPfVThGA6qrwRuZmvafnyfpMNJbQEMXxVGzSsihjz3UYVjOKg0ZYR3S/qepHEze87MrpP0OTM7ZGaPSXqXpE/kHCeANlUYNa+IGPLcRxWO4aDSVKFsiVl8Rw6xAEipCqPmFRFDnvuowjEcFKMRAkDFMRohACwyJHAACBQJHAACRQIHgECRwAEgUCRwAAgUCRwAAkUCB4BAkcABIFAkcAAIFAkcAAJFAgeAQJHAASBQJHAACBQJHAACRQIHgECRwAEgUCRwAAgUCRwAAkUCB4BAkcABIFAkcAAIFAkcAAJFAgeAQJHAASBQJHAACBQJHAACRQIHgECRwAEgUCRwAAgUCRwAAkUCB4BAkcABIFAkcAAIFAkcAALVM4Gb2Z1mdsrMDrctW2lmD5jZsej7inzDBAB0SnMF/hVJV3Usu0nSg+5+gaQHo58BAAXqmcDd/WFJL3QsvkbSXdHjuyRNDjkuAEAP/faBr3b3E9Hj5yWtTmpoZtvMbMrMpk6fPt3n7gAAnQa+ienuLsm7rL/d3SfcfWLVqlWD7g4AEOk3gZ80szWSFH0/NbyQAABp9JvA75O0NXq8VdI3hhMOACCtNGWEd0v6nqRxM3vOzK6TdJuk3zazY5LeHf0MACjQ8l4N3H1LwqorhhwLACADPokJAIEigQNAoHp2oSDZngPT2rn3qI7PNLR2tK53vWWVHnri9PzP2zePa3LTWNlhAlikrFnGXYyJiQmfmpoqbH952nNgWjt2H1Jjdi6xjalZID8Wk8xbyX96pqERM825n9Gu849DFf8YpI0xhNcCVJmZ7Xf3ic7lXIH3aefeo12Tt/Tap5umZxrasfuQJM0n5/bkPxf9EW21m3rmBd2zf3p+fefzq6DzNSTFmLYdgOzoA+/T8ZlGpvaN2Tnt3HtUUvfk35id0937nl2wvv35VRD3GuJiTNsOQHYk8D6tHa1nfk4r6fdK/nMJ3VpZ/2jkKSmWzuVp2wHIjgTep+2bx2UZn9NK+r2S/4jFb7mfPxp5SYqlc3nadgCyI4H3aXLTmD502foFSdw6vrfUayPavnlcUjP512sjsdut10a05dJ1C9a3P78K4l5DXIxp2wHIjpuYA7hlcqMm3rQytsKiW+VF63u3KpSk7VZF+2voFmPadgCyo4wQmeVdFphm+5QmYimhjBBDkXdZYJrtU5oINNEHjkzyLgtMs31KE4EmEjgyybssMM32KU0EmkjgyCTvssA026c0EWgigSOTvMsC02yf0kSgiZuYyCTvssA026c0EWiijBAAKo4ywoqIG0Z2tF6TmfTiy7OxH+oBgDgk8AIlDSM705idb9M5tKxEbTOAeNzELFCaMcTbUdsMoBsSeIH6qVOmthlAEhJ4gfqpU6a2GUASEniBug0jG4faZgDdcBOzQEnDyFKFAqAfJPCCTW4aIykDGAoSeIxeY00zFjWAKiCBd+g11jRjUQOoCm5idug11jRjUQOoChJ4h15jTTMWNYCqoAulw9rRuqZjknGrHrvX+kH6z+l7B5AFV+Adeo013W19q398eqYh12v943sOTEtS1/WDPBfA0kQC7zC5aUy3XrtRY6N1maSx0bpuvXbj/JVut/WD9J/T9w4gK7pQYvSq1U5an0f/OX3vAJJwBT5EveZq7LZ+kOcCWJpI4EM0SP/5IM8FsDQN1IViZk9L+qmkOUmvxE35s5T0mqsxzVyOgzwXwNIy0JyYUQKfcPcfp2nPnJgAkB1zYg4BddgAqmTQPnCX9G0z229m2+IamNk2M5sys6nTp08PuLvyUIcNoGoG7UIZc/dpM3ujpAck/Zm7P5zUPtQulD0HpnXj1x6dn3C43YiZXnU/44q880r9XW9ZpYeeOM2VO4C+JHWhDJTAO3Zws6SfuftfJbUJMYF3jj7YTb02ot/9tTHds3+6a/t6beSMDwcBQDdJCbzvLhQzO8fMzm09lnSlpMP9h1hNWWaSb8zO6e59z/ZszycoAQzDIDcxV0u618xa2/knd/+3oURVIVk/6RjXzTKM7QJAp74TuLv/SNJFQ4ylkpJGH0zSmtMyzXYBYBB8ErOHLDPJ12sj2nLpup7t+QQlgGEggffQPvqg1LzClpqjEP7hZesXjEp4y+TGBaMVxrXjBiaAQQ2tCiWNEKtQAKBsfBIzg1Yd9/RMY75Pe7Rek5n04suz88vGMtR4x21zrEdNeNpPfg4yyw+AcHEF3iFL3XecuBrvbttMqgmPe07abbfaSUq1DQDVNvQ68MUqS913nLga727bTKoJTzsDzyCz/AAIG10oHYZRn925jV7bjFufdgaeQWb5ARA2rsA7DKM+u3MbvbYZtz7tDDyDzPIDIGwk8A5Z6r7jxNV4d9tmUk142hl4BpnlB0DYluxNzLjqDEkLKkXamZrj57Zbfe5ZWj4ycsZz4ipXkryutkxnLR/RTGN2QXVKXDxxlStVqELpdjwHiYsqGqCA0QjTqEoCj6vcqI2Y5NLsq9mPxwVvPEfPvfh/A9387BRSJUns8Vxmkkmzc68dz6yvKW0lDrDYkcDbXH7bdzKNb1KW1qc/42IdG63ruzf9VtEhxcpyPLO8pqTtVum1A0XggzxtQqnCCKWSJEssWV5TPxU2wFKyJG9ihlKFEUolSZZYsrymEF47UKYlmcAHrTQpQkiVJHEx1pZZ875Cm6yvKYTXDpRpSXShxM1RefbyZUO96Thsjdk57dj9mG699ld167Ub9ZlvHpmvZmnMzukz3zwiSZW4mdeKIUsViqQzXtPZyxdeSyRttwqvGaiCRX8TM83YJnHlgVWxTNIfXLZeu37w7IIKmdqIaef7LwoyoVFhAqS3ZMdCSTO2SVWTtyS9KunufQuTt9Qs0Qt1XBPGaQEGt+gT+GKoWOg2RVuor48KE2Bwiz6Bp61YWGa925SlNQtQnFArMqgwAQa36G5itk+ckFZtxDQ3V82OlGWStly6LrEPPNSKjO2bx2P7wEN9PUAZFtUVeOvGWJrk3bqmHTHT7Jzr1T72V1tmuvz8lbFX761FK15Xa46JImm0XtNZbaV1ZtLl56+c/3Rip3ptmb7w+xfrlsmN2vl7F2m0Xptft+J1tWBvYEpnzjXKXKFAfxZVFUoZH5HnY90A8rYoPkrfa17JMm6AcdMNQFmCSeCddcOtyozpmYZu2HVQn9z9WCnlgNx0A1CWYPrAe9VzvzzbTy/2YLjpBqBMwSTwqnVVLDNx0w1AqYJJ4FXrquhj3gcAGKpgEvj2zeMaqdinbfjYN4AyBZPAvz7135qr2GVv1bp1ACwtQSTwPQem9d2nXig7jAWq1q0DYGkJIoFXsauCChQAZQsigVdxAuKzly/TJ3Yd1OW3fUd7DkyXHQ6AJajyCXzPgWlV69Zlc5yTmcasXM0/Ljt2HyKJAyhc5RP4Z755pFITLsTN3sNEBADKUOkEvufA9PyciVUwYpb4x4SKFABFGyiBm9lVZnbUzJ40s5uGFVRL1a5qP/+BixKHfqUiBUDR+k7gZjYi6YuS3iPpQklbzOzCYQUmVeuqdrRe0+SmMW3fPK56beSMdVSkACjDIFfgb5P0pLv/yN1/LumfJV0znLCaqnJVW6+N6Ob3vlUSExEAqI5BhpMdk/Rs28/PSbq0s5GZbZO0TZLWr1+faQfbN4/rxq8/WsgnMEfMtOXSdbplcuP8uOPHZxpa2zbeeMvkpjESNoDS5T4euLvfLul2qTkjT5bntpLkp+49pP/9efJQsi1xFSJSs/ujdQXdLTG375cEDaDqBkng05LWtf38y9GyoRp2MiUxA1gsBukD/09JF5jZr5jZWZI+KOm+4YQFAOil7ytwd3/FzK6XtFfSiKQ73f3I0CIDAHQ1UB+4u98v6f4hxQIAyKDSn8QEACQjgQNAoMy9uKGizOy0pGdSND1P0o9zDqcfVYyrijFJxJVVFeOqYkzS0ozrTe6+qnNhoQk8LTObcveJsuPoVMW4qhiTRFxZVTGuKsYkEVc7ulAAIFAkcAAIVFUT+O1lB5CginFVMSaJuLKqYlxVjEkirnmV7AMHAPRW1StwAEAPJHAACFSpCbzXlGxmdraZ7YrW7zOzDTnHs87MHjKzH5rZETP7eEybd5rZT8zsYPT16Txjatvv02Z2KNrnVMx6M7O/iY7VY2Z2SQExjbcdh4Nm9pKZ3dDRppDjZWZ3mtkpMzvctmylmT1gZsei7ysSnrs1anPMzLYWENdOM3siOk/3mtlownO7nvMhx3SzmU23naerE56b2zSKCXHtaovpaTM7mPDcXI5VtO3YvFCF95fcvZQvNQfAekrSmyWdJelRSRd2tPlTSX8XPf6gpF05x7RG0iXR43Ml/VdMTO+U9K8lHK+nJZ3XZf3Vkr6l5rDol0naV8L5fF7NDxwUfrwkvUPSJZIOty37nKSbosc3SfpszPNWSvpR9H1F9HhFznFdKWl59PizcXGlOedDjulmSX+e4hx3/Z0ddlwd6z8v6dNFHqto27F5oQrvrzKvwNNMyXaNpLuix/8i6Qozs7wCcvcT7v5I9Pinkh5Xc+ahEFwj6R+86fuSRs1sTYH7v0LSU+6e5pO2Q+fuD0t6oWNx+/vnLkmTMU/dLOkBd3/B3V+U9ICkq/KMy92/7e6vRD9+X82x9AuTcKzSyHUaxW5xRb/3H5B097D2l1aXvFD6+6vMBB43JVtnspxvE73hfyLpF4sILuqu2SRpX8zqXzezR83sW2b21iLiUXOyoW+b2X5rTlPXKc3xzNMHlfzLVcbxkqTV7n4ievy8pNUxbco+bh9R8z+nOL3O+bBdH3Xr3JnQHVDmsfpNSSfd/VjC+kKOVUdeKP39xU3MGGb2ekn3SLrB3V/qWP2Imt0EF0n6W0l7Cgrr7e5+iaT3SPqYmb2joP32ZM0JPd4r6esxq8s6Xmfw5v+zlaqZNbNPSXpF0lcTmhR5zr8k6XxJF0s6oWZ3RZVsUfer79yPVbe8UNb7q8wEnmZKtvk2ZrZc0hsk/U+eQZlZTc2T9FV339253t1fcvefRY/vl1Qzs/PyjCna13T0/ZSke9X8d7ZdIVPcJXiPpEfc/WTnirKOV+Rkqxsp+n4qpk0px83M/ljS70j6UPTLv0CKcz407n7S3efc/VVJX07YV1nHarmkayXtSmqT97FKyAulv7/KTOBppmS7T1Lrru37JX0n6c0+DFE/2x2SHnf3LyS0+aVWP7yZvU3NY5j3H5VzzOzc1mM1b4Id7mh2n6QPW9Nlkn7S9u9d3hKvjso4Xm3a3z9bJX0jps1eSVea2Yqo2+DKaFluzOwqSX8h6b3u/nJCmzTnfJgxtd8veV/CvsqaRvHdkp5w9+fiVuZ9rLrkhfLfX3nctc1wd/dqNe/oPiXpU9Gyv1TzjS1Jv6Dmv+VPSvqBpDfnHM/b1fw36DFJB6OvqyV9VNJHozbXSzqi5h3470v6jQKO05uj/T0a7bt1rNrjMklfjI7lIUkTBZ3Dc9RMyG9oW1b48VLzD8gJSbNq9jNep+b9kgclHZP075JWRm0nJP1923M/Er3HnpT0JwXE9aSa/aKt91ir0mqtpPu7nfMcY/rH6H3zmJqJaU1nTNHPC35n84wrWv6V1vuprW0hxyraflJeKP39xUfpASBQ3MQEgECRwAEgUCRwAAgUCRwAAkUCB4BAkcABIFAkcAAI1P8DFUzrbyRqkkUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJuFovxbvVUj"
      },
      "source": [
        "x1=np.loadtxt(PATH+'patchresult3/batsize10_0.9444401022864063_pred69_norm_patch_b0.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "DoCwib8o2_BJ",
        "outputId": "04a1f75d-82df-4129-b1ee-bc7e88d61d2f"
      },
      "source": [
        "plt.plot(x1,y,'o')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7efb3535c2d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeVdNr42vapW",
        "outputId": "3f019a07-0bb9-4279-d2f8-8de009bf98e3"
      },
      "source": [
        "stats.spearmanr(x,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SpearmanrResult(correlation=0.7387324181484703, pvalue=7.912146057155815e-75)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNESXa16xfk_",
        "outputId": "fdd1e20c-8868-4b4e-f442-4294c1dcb62b"
      },
      "source": [
        "stats.kendalltau(x,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KendalltauResult(correlation=0.5688278288887137, pvalue=1.3237586820729952e-65)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9gt4BZz4uxT"
      },
      "source": [
        "import os\r\n",
        "nopatchpath=PATH+'nopatchresult3'\r\n",
        "patchpath=PATH+'patchresult3'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GO80QtN47vk"
      },
      "source": [
        "file_list_nopat=os.listdir(nopatchpath)\r\n",
        "file_list=os.listdir(patchpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URD5CvAe6o5z"
      },
      "source": [
        "for i in range(len(file_list_nopat)):\r\n",
        "  file_list_nopat[i]=file_list_nopat[i].split('_')\r\n",
        "  file_list[i]=file_list[i].split('_')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "787vkb0b669H",
        "outputId": "d3b82b1c-f591-4198-c3ef-e073c4eb8110"
      },
      "source": [
        "file_list_nopat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['batsize10', '0.8116379881648721', 'pred4', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9351931137419167', 'pred9', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9072202692399882', 'pred14', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9260997282746999', 'pred19', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9151920155390321', 'pred24', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9123351570861127', 'pred29', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.8962720994802', 'pred34', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9193637286784673', 'pred39', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9195008863225032', 'pred44', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9271741744732681', 'pred49', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9265419014281016', 'pred54', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9155099785016605', 'pred59', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9384125742797408', 'pred64', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9158804780984294', 'pred69', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9178986700340237', 'pred74', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9171690074774168', 'pred79', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.8682127666228485', 'pred84', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9148663785023227', 'pred89', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9319186225607482', 'pred94', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9262027826063304', 'pred99', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9321073732669123', 'pred104', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9234030342674684', 'pred109', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9239044092006876', 'pred114', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.915524613166346', 'pred119', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9173704118148237', 'pred124', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9106589866167272', 'pred129', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.8938923947257016', 'pred134', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9208012251629794', 'pred139', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9209096170597476', 'pred144', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9198658821796248', 'pred149', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.919441457776141', 'pred154', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9145582384178789', 'pred159', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9233455026475761', 'pred164', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9166206390597593', 'pred169', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9104677999720091', 'pred174', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.881795894466957', 'pred179', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9175071662858697', 'pred184', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9167111046850533', 'pred189', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9197174713820507', 'pred194', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9182724682417915', 'pred199', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9218022494629958', 'pred204', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9171219294216844', 'pred209', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9213572006806287', 'pred214', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9040870793473182', 'pred219', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9126038030449694', 'pred224', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9125308852962384', 'pred229', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9214099804569167', 'pred234', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.862900806800662', 'pred239', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9170911862873852', 'pred244', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9210765765932536', 'pred249', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9148275072800811', 'pred254', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9117477318164683', 'pred259', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.910460696454398', 'pred264', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9053851652624291', 'pred269', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9072342041549402', 'pred274', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9063593716753324', 'pred279', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.8995513925137513', 'pred284', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9149504714913083', 'pred289', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.7597856142454967', 'pred294', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9100155222037903', 'pred299', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.8990021826023575', 'pred304', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9022669055808431', 'pred309', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9079611833465069', 'pred314', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9069449045687163', 'pred319', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9061071362214304', 'pred324', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9057400758324206', 'pred329', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.8884619772591662', 'pred334', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.8918263053705744', 'pred339', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.8988198505499603', 'pred344', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9041491015259989', 'pred349', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9089221624898886', 'pred354', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9023083950111631', 'pred359', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9049910035625458', 'pred364', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9102198181632947', 'pred369', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9146117931544062', 'pred374', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9048308982230256', 'pred379', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9157477987032802', 'pred384', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9119500108496702', 'pred389', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.8954944259186591', 'pred394', 'norm', 'nopatch', 'b0.txt'],\n",
              " ['batsize10', '0.9004061544531605', 'pred399', 'norm', 'nopatch', 'b0.txt']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW82t4hG7KyK",
        "outputId": "e348bb59-64fe-49a2-c894-ba37a7547668"
      },
      "source": [
        "print(file_list[0][1])\r\n",
        "\r\n",
        "print(float(file_list[0][1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8401987384308033\n",
            "0.8401987384308033\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36K27Xs_7VE6"
      },
      "source": [
        "nopat=np.zeros((len(file_list_nopat),1))\r\n",
        "for i in range(len(file_list_nopat)):\r\n",
        "  nopat[i]=float(file_list_nopat[i][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsaJ27n38aeA"
      },
      "source": [
        "pat=np.zeros((len(file_list),1))\r\n",
        "for i in range(len(file_list)):\r\n",
        "  pat[i]=float(file_list[i][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz17do_S8uOc"
      },
      "source": [
        "y=np.zeros((len(file_list),1))\r\n",
        "for i in range(len(file_list)):\r\n",
        "  y[i]=5*(i+1)-1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "O3TsYL6Z9L1K",
        "outputId": "177a18c9-a221-4f54-f29b-2ec152b3ab04"
      },
      "source": [
        "plt.plot(y,pat,'r',y,nopat,'g',)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-eb071efe90e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnopat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'g'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a_g2gDg9riE"
      },
      "source": [
        "np.savetxt(PATH+'patres3.txt',pat)\r\n",
        "np.savetxt(PATH+'nopatres3.txt',nopat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RL-ovUXT8fDF",
        "outputId": "c264e723-1519-4991-8f08-622057301855"
      },
      "source": [
        "pat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.84019874],\n",
              "       [0.87392702],\n",
              "       [0.88095247],\n",
              "       [0.9333725 ],\n",
              "       [0.93176452],\n",
              "       [0.9413818 ],\n",
              "       [0.92306218],\n",
              "       [0.93272258],\n",
              "       [0.75575848],\n",
              "       [0.93939771],\n",
              "       [0.94577702],\n",
              "       [0.935289  ],\n",
              "       [0.9421702 ],\n",
              "       [0.9377954 ],\n",
              "       [0.93792023],\n",
              "       [0.9419076 ],\n",
              "       [0.92724499],\n",
              "       [0.94598135],\n",
              "       [0.94525692],\n",
              "       [0.93537443],\n",
              "       [0.939474  ],\n",
              "       [0.93807919],\n",
              "       [0.9364232 ],\n",
              "       [0.93438439],\n",
              "       [0.94124439],\n",
              "       [0.94612855],\n",
              "       [0.93127403],\n",
              "       [0.94374485],\n",
              "       [0.93888467],\n",
              "       [0.78489923],\n",
              "       [0.91577642],\n",
              "       [0.94331304],\n",
              "       [0.93851253],\n",
              "       [0.93145875],\n",
              "       [0.93644648],\n",
              "       [0.93624826],\n",
              "       [0.94693085],\n",
              "       [0.93975983],\n",
              "       [0.92100232],\n",
              "       [0.92200964]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Zuvxpqa8C8M",
        "outputId": "a4b0c7ef-c366-4e99-b724-92d693ceebbb"
      },
      "source": [
        "nopat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.84345062],\n",
              "       [0.89946504],\n",
              "       [0.90448784],\n",
              "       [0.91386791],\n",
              "       [0.91759643],\n",
              "       [0.88863501],\n",
              "       [0.88004312],\n",
              "       [0.90438475],\n",
              "       [0.87271197],\n",
              "       [0.89972173],\n",
              "       [0.90784555],\n",
              "       [0.89183228],\n",
              "       [0.88747658],\n",
              "       [0.89497961],\n",
              "       [0.93049925],\n",
              "       [0.91803476],\n",
              "       [0.9263071 ],\n",
              "       [0.93108849],\n",
              "       [0.91496374],\n",
              "       [0.91907563],\n",
              "       [0.93626964],\n",
              "       [0.88462921],\n",
              "       [0.91180522],\n",
              "       [0.88261361],\n",
              "       [0.92487993],\n",
              "       [0.90000799],\n",
              "       [0.92721823],\n",
              "       [0.92611798],\n",
              "       [0.90741161],\n",
              "       [0.93078029],\n",
              "       [0.90183916],\n",
              "       [0.91717178],\n",
              "       [0.87961872],\n",
              "       [0.9216265 ],\n",
              "       [0.91031418],\n",
              "       [0.9161509 ],\n",
              "       [0.91696394],\n",
              "       [0.90908246],\n",
              "       [0.92423613],\n",
              "       [0.91849097]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    }
  ]
}